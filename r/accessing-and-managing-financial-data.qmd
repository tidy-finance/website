---
title: Accessing and Managing Financial Data
aliases: 
  - ../accessing-and-managing-financial-data.html
metadata:
  pagetitle: Accessing and Managing Financial Data with R
  description-meta: Download and organize open-source financial data using the programming language R. 
---

::: callout-note
You are reading **Tidy Finance with R**. You can find the equivalent chapter for the sibling **Tidy Finance with Python** [here](../python/accessing-and-managing-financial-data.qmd).
:::

In this chapter, we suggest a way to organize your financial data. Everybody who has experience with data is also familiar with storing data in various formats like CSV, XLS, XLSX, or other delimited value storage. Reading and saving data can become very cumbersome in the case of using different data formats, both across different projects and across different programming languages. Moreover, storing data in delimited files often leads to problems with respect to column type consistency. For instance, date-type columns frequently lead to inconsistencies across different data formats and programming languages.

This chapter shows how to import different open source data sets. Specifically, our data comes from the application programming interface (API) of Yahoo Finance, a downloaded standard CSV file, an XLSX file stored in a public Google Drive repository, and other macroeconomic time series that can be scraped directly from a website.\index{API}\index{Web scraping} We show how to process these raw data, as well as how to take a shortcut using the `tidyfinance` package, which provides a consistent interface to tidy financial data. We store all the data in a *single* database, which serves as the only source of data in subsequent chapters. We conclude the chapter by providing some tips on managing databases.\index{Database}

First, we load the global R packages that we use throughout this chapter. Later on, we load more packages in the sections where we need them.

```{r}
#| message: false
library(tidyverse)
library(tidyfinance)
library(scales)
```

Moreover, we initially define the date range for which we fetch and store the financial data, making future data updates tractable. In case you need another time frame, you can adjust the dates below. Our data starts with 1960 since most asset pricing studies use data from 1962 on.

```{r}
start_date <- ymd("1960-01-01")
end_date <- ymd("2024-12-31")
```

## Fama-French Data

We start by downloading some famous Fama-French factors [e.g., @Fama1993] and portfolio returns commonly used in empirical asset pricing. Fortunately, there is a neat package by [Nelson Areal](https://github.com/nareal/frenchdata/) that allows us to access the data easily: the `frenchdata` package provides functions to download and read data sets from [Prof. Kenneth French finance data library](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html) [@frenchdata].\index{Data!Fama-French factors} \index{Kenneth French homepage}

```{r}
#| message: false
library(frenchdata)
```

We can use the `download_french_data()` function of the package to download monthly Fama-French factors. The set *Fama/French 3 Factors* contains the return time series of the market `mkt_excess`, size `smb` and value `hml` alongside the risk-free rates `risk_free`. Note that we have to do some manual work to correctly parse all the columns and scale them appropriately, as the raw Fama-French data comes in a very unpractical data format. For precise descriptions of the variables, we suggest consulting Prof. Kenneth French's finance data library directly. If you are on the website, check the raw data files to appreciate the time you can save thanks to `frenchdata`.\index{Factor!Market}\index{Factor!Size}\index{Factor!Value}\index{Factor!Profitability}\index{Factor!Investment}\index{Risk-free rate}

```{r}
#| message: false
factors_ff3_monthly_raw <- download_french_data("Fama/French 3 Factors")
factors_ff3_monthly <- factors_ff3_monthly_raw$subsets$data[[1]] |>
  mutate(
    date = floor_date(ymd(str_c(date, "01")), "month"),
    across(c(RF, `Mkt-RF`, SMB, HML), ~ as.numeric(.) / 100),
    .keep = "none"
  ) |>
  rename_with(str_to_lower) |>
  rename(mkt_excess = `mkt-rf`, risk_free = rf) |>
  filter(date >= start_date & date <= end_date)
```

We also download the set *5 Factors (2x3)*, which additionally includes the return time series of the profitability `rmw` and investment `cma` factors. We demonstrate how the monthly factors are constructed in the chapter [Replicating Fama and French Factors](replicating-fama-and-french-factors.qmd).

```{r}
#| message: false
factors_ff5_monthly_raw <- download_french_data("Fama/French 5 Factors (2x3)")

factors_ff5_monthly <- factors_ff5_monthly_raw$subsets$data[[1]] |>
  mutate(
    date = floor_date(ymd(str_c(date, "01")), "month"),
    across(c(RF, `Mkt-RF`, SMB, HML, RMW, CMA), ~ as.numeric(.) / 100),
    .keep = "none"
  ) |>
  rename_with(str_to_lower) |>
  rename(mkt_excess = `mkt-rf`, risk_free = rf) |>
  filter(date >= start_date & date <= end_date)
```

It is straightforward to download the corresponding *daily* Fama-French factors with the same function.

```{r}
#| message: false
factors_ff3_daily_raw <- download_french_data("Fama/French 3 Factors [Daily]")

factors_ff3_daily <- factors_ff3_daily_raw$subsets$data[[1]] |>
  mutate(
    date = ymd(date),
    across(c(RF, `Mkt-RF`, SMB, HML), ~ as.numeric(.) / 100),
    .keep = "none"
  ) |>
  rename_with(str_to_lower) |>
  rename(mkt_excess = `mkt-rf`, risk_free = rf) |>
  filter(date >= start_date & date <= end_date)
```

In a subsequent chapter, we also use the 10 monthly industry portfolios, so let us fetch that data, too.\index{Data!Industry portfolios}

```{r}
#| message: false
industries_ff_monthly_raw <- download_french_data("10 Industry Portfolios")

industries_ff_monthly <- industries_ff_monthly_raw$subsets$data[[1]] |>
  mutate(date = floor_date(ymd(str_c(date, "01")), "month")) |>
  mutate(across(where(is.numeric), ~ . / 100)) |>
  select(date, everything()) |>
  filter(date >= start_date & date <= end_date) |>
  rename_with(str_to_lower)
```

It is worth taking a look at all available portfolio return time series from Kenneth French's homepage. You should check out the other sets by calling `get_french_data_list()`. 

To automatically download and process Fama-French data, you can also use the `tidyfinance` package with `type = "factors_ff_3_monthly"` or similar, e.g.:

```{r}
#| output: false
download_data(
  type = "factors_ff_3_monthly",
  start_date = start_date,
  end_date = end_date
)
```

The `tidyfinance` package implements the processing steps as above and returns the same cleaned data frame. The list of supported Fama-French data types can be called as follows:

```{r}
#| output: false
list_supported_types(domain = "Fama-French")
```

## q-Factors

In recent years, the academic discourse experienced the rise of alternative factor models, e.g., in the form of the @Hou2015 *q*-factor model. We refer to the [extended background](http://global-q.org/background.html) information provided by the original authors for further information. The *q* factors can be downloaded directly from the authors' homepage from within `read_csv()`.\index{Data!q-factors}\index{Factor!q-factors}

We also need to adjust this data. First, we discard information we will not use in the remainder of the book. Then, we rename the columns with the "R\_"-prescript using regular expressions and write all column names in lowercase. You should always try sticking to a consistent style for naming objects, which we try to illustrate here - the emphasis is on *try*. You can check out style guides available online, e.g., [Hadley Wickham's `tidyverse` style guide.](https://style.tidyverse.org/index.html)\index{Style guide}

```{r}
#| message: false
factors_q_monthly_link <-
  "https://global-q.org/uploads/1/2/2/6/122679606/q5_factors_monthly_2023.csv"

factors_q_monthly <- read_csv(factors_q_monthly_link) |>
  mutate(date = ymd(str_c(year, month, "01", sep = "-"))) |>
  rename_with(~ str_remove(., "R_")) |>
  rename_with(str_to_lower) |>
  mutate(across(-date, ~ . / 100)) |>
  select(date, risk_free = f, mkt_excess = mkt, everything()) |>
  filter(date >= start_date & date <= end_date)
```

Again, you can use the `tidyfinance` package for a shortcut:

```{r}
#| output: false
download_data(
  type = "factors_q5_monthly",
  start_date = start_date,
  end_date = end_date
)
```

## Macroeconomic Predictors

Our next data source is a set of macroeconomic variables often used as predictors for the equity premium. @Goyal2008 comprehensively reexamine the performance of variables suggested by the academic literature to be good predictors of the equity premium. The authors host the data updated to 2022 on [Amit Goyal's website.](https://sites.google.com/view/agoyal145) The data is an XLSX-file stored on a public Google drive location and we directly export a CSV file.\index{Data!Macro predictors}

```{r}
#| message: false
sheet_id <- "1bM7vCWd3WOt95Sf9qjLPZjoiafgF_8EG"
sheet_name <- "Monthly"
macro_predictors_url <- paste0(
  "https://docs.google.com/spreadsheets/d/",
  sheet_id,
  "/gviz/tq?tqx=out:csv&sheet=",
  sheet_name
)
macro_predictors_raw <- read_csv(macro_predictors_url)
```

Next, we transform the columns into the variables that we later use:

1.  The dividend price ratio (`dp`), the difference between the log of dividends and the log of prices, where dividends are 12-month moving sums of dividends paid on the S&P 500 index, and prices are monthly averages of daily closing prices [@Campbell1988; @Campbell2006].
2.  Dividend yield (`dy`), the difference between the log of dividends and the log of lagged prices [@Ball1978].
3.  Earnings price ratio (`ep`), the difference between the log of earnings and the log of prices, where earnings are 12-month moving sums of earnings on the S&P 500 index [@Campbell1988].
4.  Dividend payout ratio (`de`), the difference between the log of dividends and the log of earnings [@Lamont1998].
5.  Stock variance (`svar`), the sum of squared daily returns on the S&P 500 index [@Guo2006].
6.  Book-to-market ratio (`bm`), the ratio of book value to market value for the Dow Jones Industrial Average [@Kothari1997].
7.  Net equity expansion (`ntis`), the ratio of 12-month moving sums of net issues by NYSE listed stocks divided by the total end-of-year market capitalization of NYSE stocks [@Campbell2008].
8.  Treasury bills (`tbl`), the 3-Month Treasury Bill: Secondary Market Rate from the economic research database at the Federal Reserve Bank at St. Louis [@Campbell1987].
9.  Long-term yield (`lty`), the long-term government bond yield from Ibbotson's Stocks, Bonds, Bills, and Inflation Yearbook [@Goyal2008].
10. Long-term rate of returns (`ltr`), the long-term government bond returns from Ibbotson's Stocks, Bonds, Bills, and Inflation Yearbook [@Goyal2008].
11. Term spread (`tms`), the difference between the long-term yield on government bonds and the Treasury bill [@Campbell1987].
12. Default yield spread (`dfy`), the difference between BAA and AAA-rated corporate bond yields [@Fama1989].
13. Inflation (`infl`), the Consumer Price Index (All Urban Consumers) from the Bureau of Labor Statistics [@Campbell2004].

For variable definitions and the required data transformations, you can consult the material on [Amit Goyal's website](https://sites.google.com/view/agoyal145).

```{r}
macro_predictors <- macro_predictors_raw |>
  mutate(date = ym(yyyymm)) |>
  mutate(across(where(is.character), as.numeric)) |>
  mutate(
    IndexDiv = Index + D12,
    logret = log(IndexDiv) - log(lag(IndexDiv)),
    Rfree = log(Rfree + 1),
    rp_div = lead(logret - Rfree, 1), # Future excess market return
    dp = log(D12) - log(Index), # Dividend Price ratio
    dy = log(D12) - log(lag(Index)), # Dividend yield
    ep = log(E12) - log(Index), # Earnings price ratio
    de = log(D12) - log(E12), # Dividend payout ratio
    tms = lty - tbl, # Term spread
    dfy = BAA - AAA # Default yield spread
  ) |>
  select(
    date,
    rp_div,
    dp,
    dy,
    ep,
    de,
    svar,
    bm = `b/m`,
    ntis,
    tbl,
    lty,
    ltr,
    tms,
    dfy,
    infl
  ) |>
  filter(date >= start_date & date <= end_date) |>
  drop_na()
```

To get the equivalent data through `tidyfinance`, you can call:

```{r}
#| output: false
download_data(
  type = "macro_predictors_monthly",
  start_date = start_date,
  end_date = end_date
)
```

## Other Macroeconomic Data

The Federal Reserve bank of St. Louis provides the Federal Reserve Economic Data (FRED), an extensive database for macroeconomic data. In total, there are 817,000 US and international time series from 108 different sources. The data can be downloaded directly from FRED by constructing the appropriate URL. For instance, let us consider the consumer price index (CPI) data that can be found under the [CPIAUCNS](https://fred.stlouisfed.org/series/CPIAUCNS):\index{Data!FRED}\index{Data!CPI}

```{r}
series <- "CPIAUCNS"
cpi_url <- paste0(
  "https://fred.stlouisfed.org/graph/fredgraph.csv?id=",
  series
)
```

We can then use the `httr2` [@httr2] package to request the CSV, extract the data from the response body, and convert the columns to a tidy format:

```{r}
#| message: false
library(httr2)

resp <- request(cpi_url) |>
  req_perform()
resp_csv <- resp |>
  resp_body_string()

cpi_monthly <- resp_csv |>
  read_csv() |>
  mutate(
    date = as.Date(observation_date),
    value = as.numeric(.data[[series]]),
    series = series,
    .keep = "none"
  ) |>
  filter(date >= start_date & date <= end_date) |>
  mutate(
    cpi = value / value[date == max(date)]
  )
```

The last line sets the current (latest) price level as the reference price level.

The `tidyfinance` package can, of course, also fetch the same index data and many more data series:

```{r}
#| message: false
download_data(
  type = "fred",
  series = "CPIAUCNS",
  start_date = start_date,
  end_date = end_date
)
```

To download other time series, we just have to look it up on the FRED website and extract the corresponding key from the address. For instance, the producer price index for gold ores can be found under the [PCU2122212122210](https://fred.stlouisfed.org/series/PCU2122212122210) key. If your desired time series is not supported through `tidyfinance`, we recommend working with the `fredr` package [@fredr]. Note that you need to get an API key to use its functionality. We refer to the package documentation for details.

## Setting Up a Database

Now that we have downloaded some (freely available) data from the web into the memory of our R session let store that information for future use. We will use the data stored throughout the following chapters, but you could alternatively implement a different strategy and replace the respective code.

There are many ways to set up and organize your data, depending on the use case. Storing data as Parquet files creates a universal data format that seamlessly works across different programming languages and platforms. Unlike CSV files that often lose data types when shared between R, Python, Julia, or other languages, Parquet files maintain perfect data integrity regardless of which tool reads them. A dataset saved as Parquet in R can be opened directly in Python's pandas, or Julia's DataFrames.jl.^[In previous editions of this book, we suggested using SQLite databases. However, Parquet files are more versatile and easier to handle across different programming languages. Should you still prefer using SQLite, you can find the relevant code snippets in a separate blog post.]

```{r}
library(arrow)
```

Parquet files are easily created - the code below is really all there is. You do not need any external software. We will store everything in the data subfolder, to retrieve data for all subsequent chapters. The initial part of the code ensures that the directory is created if it does not already exist.

```{r}
if (!dir.exists("data-r")) {
  dir.create("data-r")
}
```

Next, we create file with the monthly Fama-French factor data. We do so with the function `write_parquet`.

```{r}
write_parquet(factors_ff3_monthly, "data-r/factors_ff3_monthly.parquet")
```

You can retrieve the data directly in your memory by calling `read_parquet()`. It is also possible to evaluate `dplyr` calls lazily, i.e., the data is not in our R session's memory, and the database does most of the work. 

```{r}
read_parquet("data-r/factors_ff3_monthly.parquet") |>
  select(date, risk_free) |>
  head(10)
```

Before we move on to the next data source, let us also store the other five tables in our new data folder.

```{r}
lst(
  factors_ff5_monthly,
  factors_ff3_daily,
  industries_ff_monthly,
  factors_q_monthly,
  macro_predictors,
  cpi_monthly
) |>
  iwalk(\(data, name) write_parquet(data, paste0("data-r/", name, ".parquet")))
```

## Key Takeaways

- Importing Fama-French factors, q-factors, macroeconomic indicators, and CPI data is simplified through API calls, CSV parsing, and web scraping techniques.
- The `tidyfinance` R package offers pre-processed access to financial datasets, reducing manual data cleaning and saving valuable time.
- Creating `parquet` files helps manage and organize data efficiently across projects, while maintaining reproducibility.
- Structured database storage supports scalable data access, which is essential for long-term academic projects and collaborative work in finance.

## Exercises

1.  Download the monthly Fama-French factors manually from [Ken French's data library](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html) and read them in via `read_csv()`. Validate that you get the same data as via the `frenchdata` package.
2.  Download the daily Fama-French 5 factors using the `frenchdata` package. Use `get_french_data_list()` to find the corresponding table name. After the successful download and conversion to the column format that we used above, compare the `risk_free`, `mkt_excess`, `smb`, and `hml` columns of `factors_ff3_daily` to `factors_ff5_daily`. Discuss any differences you might find.
