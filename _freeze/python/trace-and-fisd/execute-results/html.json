{
  "hash": "5ff4e7e55c33a36cb3a9c92d99a84bee",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: TRACE and FISD\nmetadata:\n    pagetitle: TRACE and FISD with Python\n    description-meta: Download and prepare corporate bond data such as TRACE and FISD from WRDS using the programming language Python. \n---\n\n\n\n::: callout-note\nYou are reading **Tidy Finance with Python**. You can find the equivalent chapter for the sibling **Tidy Finance with R** [here](../r/trace-and-fisd.qmd).\n:::\n\nIn this chapter, we dive into the US corporate bond market. Bond markets are far more diverse than stock markets, as most issuers have multiple bonds outstanding simultaneously with potentially very different indentures. This market segment is exciting due to its size (roughly ten trillion USD outstanding), heterogeneity of issuers (as opposed to government bonds), market structure (mostly over-the-counter trades), and data availability. We introduce how to use bond characteristics from FISD and trade reports from TRACE and provide code to download and clean TRACE in Python.\n\nMany researchers study liquidity in the US corporate bond market, with notable contributions from @bessembinder2006, @Edwards2007, and @Ohara2021, among many others. We do not cover bond returns here, but you can compute them from TRACE data. Instead, we refer to studies on the topic such as @Bessembinder2008, @bai2019, and @kelly2020 and a survey by @Huang2021. \n\nThis chapter also draws on the resources provided by the project [Open Source Bond Asset Pricing](https://openbondassetpricing.com/) and their related publication, i.e., @Dickerson2023. We encourage you to visit their website to check out the additional resources they provide. Moreover, WRDS provides bond returns computed from TRACE data at a monthly frequency.\\index{Corporate bonds}\n\nThe current chapter relies on the following set of Python packages. \n\n::: {#d5110155 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport tidyfinance as tf\nimport httpimport\nimport pyarrow as pa\nimport pyarrow.parquet as pq\nimport pyarrow.dataset as ds\n\nfrom plotnine import *\nfrom sqlalchemy import create_engine\nfrom mizani.formatters import comma_format\n```\n:::\n\n\n\n\nCompared to previous chapters, we load `httpimport` [@httpimport] to source code provided in the public [Gist.](https://docs.github.com/en/get-started/writing-on-github/editing-and-sharing-content-with-gists/creating-gists) Note that you should be careful with loading anything from the web via this method, and it is highly discouraged to use any unsecured \"HTTP\" links. Also, you might encounter a problem when using this from a corporate computer that prevents downloading data through a firewall.\n\n## Bond Data from WRDS \n\nBoth bond databases we need are available on [WRDS](https://wrds-www.wharton.upenn.edu/) to which we establish the PostgreSQL connection described in [WRDS, CRSP, and Compustat](wrds-crsp-and-compustat.qmd).\\index{WRDS}\n\n::: {#d4078992 .cell execution_count=4}\n``` {.python .cell-code}\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\n\nconnection_string = (\n    \"postgresql+psycopg2://\"\n    f\"{os.getenv('WRDS_USER')}:{os.getenv('WRDS_PASSWORD')}\"\n    \"@wrds-pgdata.wharton.upenn.edu:9737/wrds\"\n)\n\nwrds = create_engine(connection_string, pool_pre_ping=True)\n```\n:::\n\n\n## Mergent FISD\n\nFor research on US corporate bonds, the Mergent Fixed Income Securities Database (FISD) is the primary resource for bond characteristics.\\index{Data!FISD} There is a [detailed manual](https://wrds-www.wharton.upenn.edu/documents/1364/FixedIncome_Securities_Master_Database_User_Guide_v4.pdf) on WRDS, so we only cover the necessary subjects here. FISD data comes in two main variants, namely, centered on issuers or issues. In either case, the most useful identifiers are [CUSIPs.](https://www.cusip.com/index.html) 9-digit CUSIPs identify securities issued by issuers. The issuers can be identified from the first six digits of a security CUSIP, which is also called a 6-digit CUSIP. Both stocks and bonds have CUSIPs.\\index{CUSIP} This connection would, in principle, allow matching them easily, but due to changing issuer details, this approach only yields small coverage.\n\nWe use the issue-centered version of FISD to identify the subset of US corporate bonds that meet the standard criteria [@bessembinder2006]. The WRDS table `fisd_mergedissue` contains most of the information we need on a 9-digit CUSIP level. Due to the diversity of corporate bonds, details in the indenture vary significantly. We focus on common bonds that make up the majority of trading volume in this market without diverging too much in indentures. \n\nThe following chunk connects to the data and selects the bond sample to remove certain bond types that are less commonly used [see, e.g., @Dick2012; @Ohara2021, among many others]. In particular, we use the filters listed below. Note that we also treat missing values in these flags.\n\n1. Keep only senior bonds (`security_level = 'SEN'`).\n1. Exclude bonds which are secured lease obligations (`slob = 'N' OR slob IS NULL`).\n1. Exclude secured bonds (`security_pledge IS NULL`).\n1. Exclude asset-backed bonds (`asset_backed = 'N' OR asset_backed IS NULL`).\n1. Exclude defeased bonds (`(defeased = 'N' OR defeased IS NULL) AND defeased_date IS NULL`).\n1. Keep only the bond types US Corporate Debentures (`'CDEB'`), US Corporate Medium Term Notes (`'CMTN'`), US Corporate Zero Coupon Notes and Bonds (`'CMTZ'`, `'CZ'`), and US Corporate Bank Note (`'USBN'`).\n1. Exclude bonds that are payable in kind (`(pay_in_kind != 'Y' OR pay_in_kind IS NULL) AND pay_in_kind_exp_date IS NULL`).\n1. Exclude foreign (`yankee == \"N\" OR is.na(yankee)`) and Canadian issuers (`canadian = 'N' OR canadian IS NULL`). \n1. Exclude bonds denominated in foreign currency (`foreign_currency = 'N'`).\n1. Keep only fixed (`F`) and zero (`Z`) coupon bonds with additional requirements of `fix_frequency IS NULL`, `coupon_change_indicator = 'N'` and annual, semi-annual, quarterly, or monthly interest frequencies. \n1. Exclude bonds that were issued under SEC Rule 144A (`rule_144a = 'N'`).\n1. Exlcude privately placed bonds (`private_placement = 'N' OR private_placement IS NULL`).\n1. Exclude defaulted bonds (`defaulted = 'N' AND filing_date IS NULL AND settlement IS NULL`).\n1. Exclude convertible (`convertible = 'N'`), putable (`putable = 'N' OR putable IS NULL`), exchangeable (`exchangeable = 'N' OR exchangeable IS NULL`), perpetual (`perpetual = 'N'`), or preferred bonds (`preferred_security = 'N' OR preferred_security IS NULL`).\n1. Exclude unit deal bonds (`(unit_deal = 'N' OR unit_deal IS NULL)`).\n\n::: {#0831f304 .cell execution_count=5}\n``` {.python .cell-code}\nfisd_query = (\n  \"SELECT complete_cusip, maturity, offering_amt, offering_date, \"\n         \"dated_date, interest_frequency, coupon, last_interest_date, \"\n         \"issue_id, issuer_id \"\n    \"FROM fisd.fisd_mergedissue \"\n    \"WHERE security_level = 'SEN' \"\n          \"AND (slob = 'N' OR slob IS NULL) \"\n          \"AND security_pledge IS NULL \"              \n          \"AND (asset_backed = 'N' OR asset_backed IS NULL) \"\n          \"AND (defeased = 'N' OR defeased IS NULL) \"\n          \"AND defeased_date IS NULL \"\n          \"AND bond_type IN ('CDEB', 'CMTN', 'CMTZ', 'CZ', 'USBN') \"\n          \"AND (pay_in_kind != 'Y' OR pay_in_kind IS NULL) \"\n          \"AND pay_in_kind_exp_date IS NULL \"\n          \"AND (yankee = 'N' OR yankee IS NULL) \"\n          \"AND (canadian = 'N' OR canadian IS NULL) \"\n          \"AND foreign_currency = 'N' \"\n          \"AND coupon_type IN ('F', 'Z') \"\n          \"AND fix_frequency IS NULL \"\n          \"AND coupon_change_indicator = 'N' \"\n          \"AND interest_frequency IN ('0', '1', '2', '4', '12') \"\n          \"AND rule_144a = 'N' \"\n          \"AND (private_placement = 'N' OR private_placement IS NULL) \"\n          \"AND defaulted = 'N' \"\n          \"AND filing_date IS NULL \"\n          \"AND settlement IS NULL \"\n          \"AND convertible = 'N' \"\n          \"AND exchange IS NULL \"\n          \"AND (putable = 'N' OR putable IS NULL) \"\n          \"AND (unit_deal = 'N' OR unit_deal IS NULL) \"\n          \"AND (exchangeable = 'N' OR exchangeable IS NULL) \"\n          \"AND perpetual = 'N' \"\n          \"AND (preferred_security = 'N' OR preferred_security IS NULL)\"\n)\n\nfisd = pd.read_sql_query(\n    sql=fisd_query,\n    con=wrds,\n    dtype={\"complete_cusip\": str, \"interest_frequency\": str, \n            \"issue_id\": int, \"issuer_id\": int},\n    parse_dates={\"maturity\", \"offering_date\", \n                \"dated_date\", \"last_interest_date\"}\n)\n```\n:::\n\n\nWe also pull issuer information from `fisd_mergedissuer` regarding the industry and country of the firm that issued a particular bond. Then, we filter to include only US-domiciled firms' bonds. We match the data by `issuer_id`.\n\n::: {#09dfee83 .cell execution_count=6}\n``` {.python .cell-code}\nfisd_issuer_query = (\n    \"SELECT issuer_id, sic_code, country_domicile \"\n        \"FROM fisd.fisd_mergedissuer\"\n)\n\nfisd_issuer = pd.read_sql_query(\n    sql=fisd_issuer_query,\n    con=wrds,\n    dtype={\"issuer_id\": int, \"sic_code\": str, \"country_domicile\": str}\n)\n\nfisd = (fisd\n    .merge(fisd_issuer, how=\"inner\", on=\"issuer_id\")\n    .query(\"country_domicile == 'USA'\")\n    .drop(columns=\"country_domicile\")\n)\n```\n:::\n\n\nTo download the FISD data with the above filters and processing steps, you can use the `tidyfinance` package. Note that you might have to set the login credentials for WRDS first using `tf.set_wrds_credentials()`.\n\n::: {#f3f8e096 .cell execution_count=7}\n``` {.python .cell-code}\nfisd = tf.download_data(domain=\"wrds\", dataset=\"fisd\")\n```\n:::\n\n\nFinally, we save the bond characteristics to our local folder. This selection of bonds also constitutes the sample for which we will collect trade reports from TRACE below.\n\n::: {#15380077 .cell execution_count=8}\n``` {.python .cell-code}\nfisd.to_parquet(\"data-python/fisd.parquet\")\n```\n:::\n\n\nThe FISD database also contains other data. The issue-based file contains information on covenants, i.e., restrictions included in bond indentures to limit specific actions by firms [e.g., @handler2021]. The FISD redemption database also contains information on callable bonds. Moreover, FISD also provides information on bond ratings. We do not need either here.\n\n\n\n## TRACE\n\nThe Financial Industry Regulatory Authority (FINRA) provides the Trade Reporting and Compliance Engine (TRACE).\\index{Data!TRACE} In TRACE, dealers that trade corporate bonds must report such trades individually. Hence, we observe trade messages in TRACE that contain information on the bond traded, the trade time, price, and volume. TRACE comes in two variants: standard and enhanced TRACE. We show how to download and clean enhanced TRACE as it contains uncapped volume, a crucial quantity missing in the standard distribution. Moreover, enhanced TRACE also provides information on the respective parties' roles and the direction of the trade report. These items become essential in cleaning the messages.\n\nWhy do we repeatedly talk about cleaning TRACE? Trade messages are submitted within a short time window after a trade is executed (less than 15 minutes). These messages can contain errors, and the reporters subsequently correct them or they cancel a trade altogether. The cleaning needs are described by @Dick2009 in detail, and @Dick2014 shows how to clean the enhanced TRACE data using SAS. We do not go into the cleaning steps here, since the code is lengthy and is not our focus here. However, downloading and cleaning enhanced TRACE data is straightforward with our setup.\n\nWe store code for cleaning enhanced TRACE with Python on the following GitHub [Gist.](https://gist.githubusercontent.com/patrick-weiss/86ddef6de978fbdfb22609a7840b5d8b) \\index{GitHub!Gist} [Clean Enhanced TRACE with Python](clean-enhanced-trace-with-python.qmd) also contains the code for reference. We only need to source the code from the Gist, which we can do with the code below using `httpimport`. In the chunk, we explicitly load the necessary function interpreting the Gist as a module (i.e., you could also use it as a module and precede the function calls with the module's name). Alternatively, you can also go to the Gist, download it, and manually execute it. The `clean_enhanced_trace()` function takes a vector of CUSIPs, a connection to WRDS explained in [WRDS, CRSP, and Compustat](wrds-crsp-and-compustat.qmd), and a start and end date, respectively. \n\n::: {#822a0d25 .cell execution_count=10}\n``` {.python .cell-code}\nimport requests\n\nurl = (\n    \"https://gist.githubusercontent.com/patrick-weiss/\"\n    \"86ddef6de978fbdfb22609a7840b5d8b/raw/\"\n    \"8fbcc6c6f40f537cd3cd37368be4487d73569c6b/\"\n)\n\nresponse = requests.get(url, verify=False)\nexec(response.text)\n```\n:::\n\n\nThe TRACE database is considerably large. Therefore, we only download subsets of data at once. Specifying too many CUSIPs over a long time horizon will result in very long download times and a potential failure due to the size of the request to WRDS. The size limit depends on many parameters, and we cannot give you a guideline here. For the applications in this book, we need data around the Paris Agreement in December 2015 and download the data in sets of 1,000 bonds, which we define below.\\index{Paris (Climate) Agreement}\n\n::: {#29c04269 .cell execution_count=11}\n``` {.python .cell-code}\ncusips = list(fisd[\"complete_cusip\"].unique())\nbatch_size = 1000\nbatches = np.ceil(len(cusips)/batch_size).astype(int)\n```\n:::\n\n\nFinally, we run a loop in the same style as in [WRDS, CRSP, and Compustat](wrds-crsp-and-compustat.qmd) where we download daily returns from CRSP. For each of the CUSIP sets defined above, we call the cleaning function and save the resulting output. We add new data to the existing dataset for batch two and all following batches.  Because our later applications load the entire table at once, we partition the data by batch rather than by security identifier. Using a smaller number of larger files improves efficiency when loading the full dataset into memory.\n\n::: {#24fb932d .cell execution_count=12}\n``` {.python .cell-code}\nfor j in range(1, batches + 1):\n  \n    cusip_batch = cusips[\n            ((j-1)*batch_size):(min(j*batch_size, len(cusips)))\n    ]\n    \n    cusip_batch_formatted = \", \".join(f\"'{cusip}'\" for cusip in cusip_batch)\n    cusip_string = f\"({cusip_batch_formatted})\"\n\n    trace_enhanced_sub = clean_enhanced_trace(\n            cusips=cusip_string,\n            connection=wrds, \n            start_date=\"'01/01/2014'\", \n            end_date=\"'11/30/2016'\"\n    )\n    \n    if not trace_enhanced_sub.empty:\n            table = (pa.Table.from_pandas(trace_enhanced_sub, preserve_index=False)\n                .append_column(\"batch\", pa.array([j] * len(trace_enhanced_sub)))\n            )\n            pq.write_to_dataset(\n                table,\n                root_path=\"data-python/trace_enhanced\",\n                partition_cols=[\"batch\"],\n                existing_data_behavior=\"overwrite_or_ignore\"\n            )\n        \n    print(f\"Batch {j} out of {batches} done ({(j/batches)*100:.2f}%)\\n\")\n```\n:::\n\n\nIf you want to download the prepared enhanced TRACE data for selected bonds via the `tidyfinance` package, you can call, e.g.:\n\n::: {#bc82bf80 .cell execution_count=13}\n``` {.python .cell-code}\ntf.download_data(\n    domain=\"wrds\",\n    dataset=\"trace_enhanced\",\n    cusips=[\"00101JAH9\"],\n    start_date=\"2019-01-01\", \n    end_date=\"2021-12-31\"\n)\n```\n:::\n\n\n## Insights into Corporate Bonds\n\nWhile many news outlets readily provide information on stocks and the underlying firms, corporate bonds are not covered frequently. Additionally, the TRACE database contains trade-level information, potentially new to students. Therefore, we provide you with some insights by showing some summary statistics.\\index{Summary statistics}\n\nWe start by looking into the number of bonds outstanding over time and compare it to the number of bonds traded in our sample. First, we compute the number of bonds outstanding for each quarter around the Paris Agreement from 2014 to 2016. \n\n::: {#292dd3f8 .cell execution_count=14}\n``` {.python .cell-code}\ndates = pd.date_range(start=\"2014-01-01\", end=\"2016-11-30\", freq=\"QE\")\n\nbonds_outstanding = (pd.DataFrame({\"date\": dates})\n    .merge(fisd[[\"complete_cusip\"]], how=\"cross\")\n    .merge(fisd[[\"complete_cusip\", \"offering_date\", \"maturity\"]],\n            on=\"complete_cusip\", how=\"left\")\n    .assign(offering_date=lambda x: x[\"offering_date\"].dt.floor(\"D\"),\n            maturity=lambda x: x[\"maturity\"].dt.floor(\"D\"))\n    .query(\"date >= offering_date & date <= maturity\")\n    .groupby(\"date\")\n    .size()\n    .reset_index(name=\"count\")\n    .assign(type=\"Outstanding\")\n)\n```\n:::\n\n\nNext, we look at the bonds traded each quarter in the same period. Notice that we load the complete TRACE data from our dataset, as we only have a single part of it in the environment from the download loop above.\n\n::: {#822395c1 .cell execution_count=15}\n``` {.python .cell-code}\ntrace_enhanced = ds.dataset(\"data-python/trace_enhanced\", format=\"parquet\").to_table().to_pandas()\n\nbonds_traded = (trace_enhanced\n    .assign(\n        date=lambda x: (\n        (x[\"trd_exctn_dt\"]-pd.offsets.MonthBegin(1))\n            .dt.to_period(\"Q\").dt.start_time\n        )\n    )\n    .groupby(\"date\")\n    .aggregate(count=(\"cusip_id\", \"nunique\"))\n    .reset_index()\n    .assign(type=\"Traded\")\n)\n```\n:::\n\n\nFinally, we plot the two time series in @fig-401.\n\n::: {#cell-fig-401 .cell execution_count=16}\n``` {.python .cell-code}\nbonds_combined = pd.concat(\n    [bonds_outstanding, bonds_traded], ignore_index=True\n)\n\nbonds_figure = (\n    ggplot(\n        bonds_combined, \n        aes(x=\"date\", y=\"count\", color=\"type\", linetype=\"type\")\n    )\n    + geom_line()\n    + labs(\n        x=\"\", y=\"\", color=\"\", linetype=\"\",\n        title=\"Number of bonds outstanding and traded each quarter\"\n        )\n    + scale_x_datetime(date_breaks=\"1 year\", date_labels=\"%Y\")\n    + scale_y_continuous(labels=comma_format())\n)\nbonds_figure.draw()\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n![Number of corporate bonds outstanding each quarter as reported by Mergent FISD and the number of traded bonds from enhanced TRACE between 2014 and end of 2016.](trace-and-fisd_files/figure-html/fig-401-output-1.png){#fig-401 width=2160 height=1560 fig-alt='Title: Number of bonds outstanding and traded each quarter. The figure shows a time series of outstanding bonds and bonds traded. The amount outstanding increases monotonically between 2014 and 2016. The number of bonds traded represents only a fraction of roughly 60 percent, which peaks around the third quarter of 2016.' fig-pos='htb'}\n:::\n:::\n\n\nWe see that the number of bonds outstanding increases steadily between 2014 and 2016. During our sample period of trade data, we see that the fraction of bonds trading each quarter is roughly 60 percent. The relatively small number of traded bonds means that many bonds do not trade through an entire quarter. This lack of trading activity illustrates the generally low level of liquidity in the corporate bond market, where it can be hard to trade specific bonds. Does this lack of liquidity mean that corporate bond markets are irrelevant in terms of their size? With over 7,500 traded bonds each quarter, it is hard to say that the market is small. However, let us also investigate the characteristics of issued corporate bonds. In particular, we consider maturity (in years), coupon, and offering amount (in million USD).\\index{Liquidity}\n\n::: {#01c0216c .cell execution_count=17}\n``` {.python .cell-code}\naverage_characteristics = (fisd\n    .assign(\n        maturity=lambda x: (x[\"maturity\"] - x[\"offering_date\"]).dt.days/365,\n        offering_amt=lambda x: x[\"offering_amt\"]/10**3\n    )\n    .melt(var_name=\"measure\",\n            value_vars=[\"maturity\", \"coupon\", \"offering_amt\"], \n            value_name=\"value\")\n    .dropna()\n    .groupby(\"measure\")[\"value\"]\n    .describe(percentiles=[.05, .50, .95])\n    .drop(columns=\"count\")\n)\naverage_characteristics.round(2)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>5%</th>\n      <th>50%</th>\n      <th>95%</th>\n      <th>max</th>\n    </tr>\n    <tr>\n      <th>measure</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>coupon</th>\n      <td>2.34</td>\n      <td>3.43</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>8.67</td>\n      <td>39.00</td>\n    </tr>\n    <tr>\n      <th>maturity</th>\n      <td>5.47</td>\n      <td>6.55</td>\n      <td>-6.24</td>\n      <td>1.04</td>\n      <td>3.52</td>\n      <td>20.01</td>\n      <td>100.74</td>\n    </tr>\n    <tr>\n      <th>offering_amt</th>\n      <td>121.20</td>\n      <td>353.41</td>\n      <td>0.00</td>\n      <td>0.22</td>\n      <td>2.64</td>\n      <td>750.00</td>\n      <td>15000.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe see that the average bond in our sample period has an offering amount of over 357 million USD with a median of 200 million USD, which both cannot be considered small. The average bond has a maturity of ten years and pays around 6 percent in coupons.\n\nFinally, let us compute some summary statistics for the trades in this market. To this end, we show a summary based on aggregate information daily. In particular, we consider the trade size (in million USD) and the number of trades.\n\n::: {#7651a133 .cell execution_count=18}\n``` {.python .cell-code}\naverage_trade_size = (trace_enhanced\n    .groupby(\"trd_exctn_dt\")\n    .aggregate(\n        trade_size=(\"entrd_vol_qt\", lambda x: (\n        sum(x*trace_enhanced.loc[x.index, \"rptd_pr\"]/100)/10**6)\n        ),\n        trade_number=(\"trd_exctn_dt\", \"size\")\n    )\n    .reset_index()\n    .melt(id_vars=[\"trd_exctn_dt\"], var_name=\"measure\",\n            value_vars=[\"trade_size\", \"trade_number\"], value_name=\"value\")\n    .groupby(\"measure\")[\"value\"]\n    .describe(percentiles=[.05, .50, .95])\n    .drop(columns=\"count\")\n)\naverage_trade_size.round(0)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>5%</th>\n      <th>50%</th>\n      <th>95%</th>\n      <th>max</th>\n    </tr>\n    <tr>\n      <th>measure</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>trade_number</th>\n      <td>25937.0</td>\n      <td>5446.0</td>\n      <td>439.0</td>\n      <td>17854.0</td>\n      <td>26072.0</td>\n      <td>34398.0</td>\n      <td>40868.0</td>\n    </tr>\n    <tr>\n      <th>trade_size</th>\n      <td>12971.0</td>\n      <td>3577.0</td>\n      <td>17.0</td>\n      <td>6128.0</td>\n      <td>13423.0</td>\n      <td>17869.0</td>\n      <td>21313.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nOn average, nearly 26 billion USD of corporate bonds are traded daily in nearly 13,000 transactions. We can, hence, conclude that the corporate bond market is indeed significant in terms of trading volume and activity.\n\n## Key Takeaways\n\n- The US corporate bond market is large, diverse, and primarily trades over-the-counter, making it an important yet complex subject of financial research.\n- The Mergent FISD database on WRDS provides detailed bond characteristics, which are essential for selecting a representative sample of US corporate bonds.\n- Enhanced TRACE data includes uncapped trade volumes and dealer roles, offering valuable insights into bond market liquidity and trade execution.\n- Cleaning TRACE data is crucial, as trades may be corrected or canceled shortly after reporting, but automated functions in the `tidyfinance` Python package simplify this task.\n\n## Exercises\n\n1. Compute the amount outstanding across all bonds over time. Make sure to subtract all matured bonds. How would you describe the resulting plot?\n1. Compute the number of days each bond is traded (accounting for the bonds' maturities and issuances). Start by looking at the number of bonds traded each day in a graph similar to the one above. How many bonds trade on more than 75 percent of trading days? \n1. WRDS provides more information from Mergent FISD such as ratings in the table `fisd_ratings`. Download the ratings table and plot the distribution of ratings for the different rating providers. How would you map the different providers to a common numeric rating scale? \\index{Rating}\n\n",
    "supporting": [
      "trace-and-fisd_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}