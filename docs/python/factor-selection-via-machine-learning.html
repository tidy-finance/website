<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Use machine learning tools such as Lasso and Ridge regressions to identify asset pricing factors using the programming language Python.">

<title>Factor Selection via Machine Learning with Python – Tidy Finance</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../python/option-pricing-via-machine-learning.html" rel="next">
<link href="../python/difference-in-differences.html" rel="prev">
<link href="../assets/img/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-9c5d9ace2f4fc3d608099a0da644ebba.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-DH3KZSMJ5W"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-DH3KZSMJ5W', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"interstitial",
  "consent_type":"express",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/css/global.css">
<meta property="og:title" content="Factor Selection via Machine Learning with Python">
<meta property="og:description" content="An opinionated approach on empirical research in financial economics">
<meta property="og:image" content="https://www.tidy-finance.org/python/factor-selection-via-machine-learning_files/figure-html/fig-1401-output-1.png">
<meta property="og:site_name" content="Tidy Finance">
<meta property="og:image:alt" content="Title: Excess return distributions by industry in percent. The figure shows boxplots that visualize the industry's excess return distribution. All industry returns are centered around zero and exhibit substantial outliers in the magnitude of 20 percent on a monthly basis.">
<meta property="og:image:height" content="814">
<meta property="og:image:width" content="1294">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../assets/img/logo-website-white.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tidy Finance</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../r/index.html"> 
<span class="menu-text">R</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../python/index.html" aria-current="page"> 
<span class="menu-text">Python</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../contribute.html"> 
<span class="menu-text">Contribute</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../support.html"> 
<span class="menu-text">Support</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.etsy.com/shop/tidyswag/?etsrc=sdt&amp;utm_source=tidy-finance.org"> 
<span class="menu-text">Swag</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://talks.tidy-finance.org"> 
<span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../workshops/reproducible-research-workflows.html"> 
<span class="menu-text">Workshops</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="../blog.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title">Factor Selection via Machine Learning</h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Tidy Finance with Python</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tidy Finance with Python</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Getting Started</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/setting-up-your-environment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setting Up Your Environment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/introduction-to-tidy-finance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Tidy Finance</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Financial Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/accessing-and-managing-financial-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Accessing and Managing Financial Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/wrds-crsp-and-compustat.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">WRDS, CRSP, and Compustat</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/trace-and-fisd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TRACE and FISD</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/other-data-providers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Other Data Providers</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Asset Pricing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/beta-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beta Estimation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/univariate-portfolio-sorts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Univariate Portfolio Sorts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/size-sorts-and-p-hacking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Size Sorts and p-Hacking</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/value-and-bivariate-sorts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Value and Bivariate Sorts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/replicating-fama-and-french-factors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Replicating Fama-French Factors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/fama-macbeth-regressions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fama-MacBeth Regressions</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Modeling and Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/fixed-effects-and-clustered-standard-errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fixed Effects and Clustered Standard Errors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/difference-in-differences.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Difference in Differences</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/factor-selection-via-machine-learning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Factor Selection via Machine Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/option-pricing-via-machine-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Option Pricing via Machine Learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Portfolio Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/parametric-portfolio-policies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Parametric Portfolio Policies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/constrained-optimization-and-backtesting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Constrained Optimization and Backtesting</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/wrds-dummy-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">WRDS Dummy Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/cover-image.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Cover Image</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/clean-enhanced-trace-with-python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clean Enhanced TRACE with Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/proofs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Proofs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/colophon.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Colophon</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../python/changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Changelog</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#brief-theoretical-background" id="toc-brief-theoretical-background" class="nav-link active" data-scroll-target="#brief-theoretical-background">Brief Theoretical Background</a>
  <ul class="collapse">
  <li><a href="#ridge-regression" id="toc-ridge-regression" class="nav-link" data-scroll-target="#ridge-regression">Ridge regression</a></li>
  <li><a href="#lasso" id="toc-lasso" class="nav-link" data-scroll-target="#lasso">Lasso</a></li>
  <li><a href="#elastic-net" id="toc-elastic-net" class="nav-link" data-scroll-target="#elastic-net">Elastic Net</a></li>
  </ul></li>
  <li><a href="#python-packages" id="toc-python-packages" class="nav-link" data-scroll-target="#python-packages">Python Packages</a></li>
  <li><a href="#data-preparation" id="toc-data-preparation" class="nav-link" data-scroll-target="#data-preparation">Data Preparation</a></li>
  <li><a href="#machine-learning-workflow" id="toc-machine-learning-workflow" class="nav-link" data-scroll-target="#machine-learning-workflow">Machine Learning Workflow</a>
  <ul class="collapse">
  <li><a href="#pre-process-data" id="toc-pre-process-data" class="nav-link" data-scroll-target="#pre-process-data">Pre-process data</a></li>
  <li><a href="#build-a-model" id="toc-build-a-model" class="nav-link" data-scroll-target="#build-a-model">Build a model</a></li>
  <li><a href="#fit-a-model" id="toc-fit-a-model" class="nav-link" data-scroll-target="#fit-a-model">Fit a model</a></li>
  <li><a href="#tune-a-model" id="toc-tune-a-model" class="nav-link" data-scroll-target="#tune-a-model">Tune a model</a></li>
  <li><a href="#full-workflow" id="toc-full-workflow" class="nav-link" data-scroll-target="#full-workflow">Full workflow</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/tidy-finance/website/blob/main/python/factor-selection-via-machine-learning.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Factor Selection via Machine Learning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>You are reading <strong>Tidy Finance with Python</strong>. You can find the equivalent chapter for the sibling <strong>Tidy Finance with R</strong> <a href="../r/factor-selection-via-machine-learning.html">here</a>.</p>
</div>
</div>
<p>The aim of this chapter is twofold. From a data science perspective, we introduce <code>scikit-learn</code>, a collection of packages for modeling and machine learning (ML). <code>scikit-learn</code> comes with a handy workflow for all sorts of typical prediction tasks. From a finance perspective, we address the notion of <em>factor zoo</em> <span class="citation" data-cites="Cochrane2011">(<a href="#ref-Cochrane2011" role="doc-biblioref">Cochrane 2011</a>)</span> using ML methods. We introduce Lasso, Ridge, and Elastic Net regression as a special case of penalized regression models. Then, we explain the concept of cross-validation for model <em>tuning</em> with Elastic Net regularization as a popular example. We implement and showcase the entire cycle from model specification, training, and forecast evaluation within the <code>scikit-learn</code> universe. While the tools can generally be applied to an abundance of interesting asset pricing problems, we apply penalized regressions for identifying macroeconomic variables and asset pricing factors that help explain a cross-section of industry portfolios.</p>
<p>In previous chapters, we illustrate that stock characteristics such as size provide valuable pricing information in addition to the market beta. Such findings question the usefulness of the Capital Asset Pricing Model. In fact, during the last decades, financial economists discovered a plethora of additional factors which may be correlated with the marginal utility of consumption (and would thus deserve a prominent role in pricing applications). The search for factors that explain the cross-section of expected stock returns has produced hundreds of potential candidates, as noted more recently by <span class="citation" data-cites="Harvey2016">Harvey, Liu, and Zhu (<a href="#ref-Harvey2016" role="doc-biblioref">2016</a>)</span>, <span class="citation" data-cites="Harvey2017">Harvey (<a href="#ref-Harvey2017" role="doc-biblioref">2017</a>)</span>, <span class="citation" data-cites="Mclean2016">Mclean and Pontiff (<a href="#ref-Mclean2016" role="doc-biblioref">2016</a>)</span>, and <span class="citation" data-cites="Hou2020">Hou, Xue, and Zhang (<a href="#ref-Hou2020" role="doc-biblioref">2020</a>)</span>. Therefore, given the multitude of proposed risk factors, the challenge these days rather is: <em>do we believe in the relevance of hundreds of risk factors?</em> During recent years, promising methods from the field of ML got applied to common finance applications. We refer to <span class="citation" data-cites="Mullainathan2017">Mullainathan and Spiess (<a href="#ref-Mullainathan2017" role="doc-biblioref">2017</a>)</span> for a treatment of ML from the perspective of an econometrician, <span class="citation" data-cites="Nagel2021">Nagel (<a href="#ref-Nagel2021" role="doc-biblioref">2021</a>)</span> for an excellent review of ML practices in asset pricing, <span class="citation" data-cites="Easley2021">Easley et al. (<a href="#ref-Easley2021" role="doc-biblioref">2020</a>)</span> for ML applications in (high-frequency) market microstructure, and <span class="citation" data-cites="Dixon2020">Dixon, Halperin, and Bilokon (<a href="#ref-Dixon2020" role="doc-biblioref">2020</a>)</span> for a detailed treatment of all methodological aspects.</p>
<section id="brief-theoretical-background" class="level2">
<h2 class="anchored" data-anchor-id="brief-theoretical-background">Brief Theoretical Background</h2>
<p>This is a book about <em>doing</em> empirical work in a tidy manner, and we refer to any of the many excellent textbook treatments of ML methods and especially penalized regressions for some deeper discussion. Excellent material is provided, for instance, by <span class="citation" data-cites="Hastie2009">Hastie, Tibshirani, and Friedman (<a href="#ref-Hastie2009" role="doc-biblioref">2009</a>)</span>, <span class="citation" data-cites="Hastie2013">Gareth et al. (<a href="#ref-Hastie2013" role="doc-biblioref">2013</a>)</span>, and <span class="citation" data-cites="DePrado2018">De Prado (<a href="#ref-DePrado2018" role="doc-biblioref">2018</a>)</span>. Instead, we briefly summarize the idea of Lasso and Ridge regressions as well as the more general Elastic Net. Then, we turn to the fascinating question on <em>how</em> to implement, tune, and use such models with the <code>scikit-learn</code> package.</p>
<p>To set the stage, we start with the definition of a linear model: Suppose we have data <span class="math inline">\((y_t, x_t), t = 1,\ldots, T\)</span>, where <span class="math inline">\(x_t\)</span> is a <span class="math inline">\((K \times 1)\)</span> vector of regressors and <span class="math inline">\(y_t\)</span> is the response for observation <span class="math inline">\(t\)</span>. The linear model takes the form <span class="math inline">\(y_t = \beta' x_t + \varepsilon_t\)</span> with some error term <span class="math inline">\(\varepsilon_t\)</span> and has been studied in abundance. For <span class="math inline">\(K\leq T\)</span>, the well-known ordinary-least square (OLS) estimator for the <span class="math inline">\((K \times 1)\)</span> vector <span class="math inline">\(\beta\)</span> minimizes the sum of squared residuals and is then <span id="eq-ols"><span class="math display">\[\hat{\beta}^\text{ols} = \left(\sum\limits_{t=1}^T x_t'x_t\right)^{-1} \sum\limits_{t=1}^T x_t'y_t. \tag{1}\]</span></span> </p>
<p>While we are often interested in the estimated coefficient vector <span class="math inline">\(\hat\beta^\text{ols}\)</span>, ML is about the predictive performance most of the time. For a new observation <span class="math inline">\(\tilde{x}_t\)</span>, the linear model generates predictions such that <span id="eq-blue"><span class="math display">\[\hat y_t = E\left(y|x_t = \tilde x_t\right) = \hat\beta^\text{ols}{}' \tilde x_t. \tag{2}\]</span></span> Is this the best we can do? Not necessarily: instead of minimizing the sum of squared residuals, penalized linear models can improve predictive performance by choosing other estimators <span class="math inline">\(\hat{\beta}\)</span> with lower variance than the estimator <span class="math inline">\(\hat\beta^\text{ols}\)</span>. At the same time, it seems appealing to restrict the set of regressors to a few meaningful ones, if possible. In other words, if <span class="math inline">\(K\)</span> is large (such as for the number of proposed factors in the asset pricing literature), it may be a desirable feature to <em>select</em> reasonable factors and set <span class="math inline">\(\hat\beta^{\text{ols}}_k = 0\)</span> for some redundant factors.</p>
<p>It should be clear that the promised benefits of penalized regressions, i.e., reducing the mean squared error (MSE), come at a cost. In most cases, reducing the variance of the estimator introduces a bias such that <span class="math inline">\(E\left(\hat\beta\right) \neq \beta\)</span>. What is the effect of such a bias-variance trade-off? To understand the implications, assume the following data-generating process for <span class="math inline">\(y\)</span>: <span id="eq-model-and-noise"><span class="math display">\[y = f(x) + \varepsilon, \quad \varepsilon \sim (0, \sigma_\varepsilon^2) \tag{3}\]</span></span> We want to recover <span class="math inline">\(f(x)\)</span>, which denotes some unknown functional which maps the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. While the properties of <span class="math inline">\(\hat\beta^\text{ols}\)</span> as an unbiased estimator may be desirable under some circumstances, they are certainly not if we consider predictive accuracy. Alternative predictors <span class="math inline">\(\hat{f}(x)\)</span> could be more desirable: For instance, the MSE depends on our model choice as follows: <span id="eq-mse"><span class="math display">\[\begin{aligned}
MSE &amp;=E\left(\left(y-\hat{f}(x)\right)^2\right)=E\left(\left(f(x)+\epsilon-\hat{f}(x)\right)^2\right)\\
&amp;= \underbrace{E\left(\left(f(x)-\hat{f}(x)\right)^2\right)}_{\text{total quadratic error}}+\underbrace{E\left(\epsilon^2\right)}_{\text{irreducible error}} \\
&amp;= E\left(\hat{f}(x)^2\right)+E\left(f(x)^2\right)-2E\left(f(x)\hat{f}(x)\right)+\sigma_\varepsilon^2\\
&amp;=E\left(\hat{f}(x)^2\right)+f(x)^2-2f(x)E\left(\hat{f}(x)\right)+\sigma_\varepsilon^2\\
&amp;=\underbrace{\text{Var}\left(\hat{f}(x)\right)}_{\text{variance of model}}+ \underbrace{\left(E(f(x)-\hat{f}(x))\right)^2}_{\text{squared bias}} +\sigma_\varepsilon^2.
\end{aligned} \tag{4}\]</span></span> While no model can reduce <span class="math inline">\(\sigma_\varepsilon^2\)</span>, a biased estimator with small variance may have a lower MSE than an unbiased estimator.</p>
<section id="ridge-regression" class="level3">
<h3 class="anchored" data-anchor-id="ridge-regression">Ridge regression</h3>
<p></p>
<p>One biased estimator is known as Ridge regression. <span class="citation" data-cites="Hoerl1970">Hoerl and Kennard (<a href="#ref-Hoerl1970" role="doc-biblioref">1970</a>)</span> propose to minimize the sum of squared errors <em>while simultaneously imposing a penalty on the <span class="math inline">\(L_2\)</span> norm of the parameters</em> <span class="math inline">\(\hat\beta\)</span>. Formally, this means that for a penalty factor <span class="math inline">\(\lambda\geq 0\)</span>, the minimization problem takes the form <span class="math inline">\(\min_\beta \left(y - X\beta\right)'\left(y - X\beta\right)\text{ s.t. } \beta'\beta \leq c\)</span>. Here <span class="math inline">\(c\geq 0\)</span> is a constant that depends on the choice of <span class="math inline">\(\lambda\)</span>. The larger <span class="math inline">\(\lambda\)</span>, the smaller <span class="math inline">\(c\)</span> (technically speaking, there is a one-to-one relationship between <span class="math inline">\(\lambda\)</span>, which corresponds to the Lagrangian of the minimization problem above and <span class="math inline">\(c\)</span>). Here, <span class="math inline">\(X = \left(x_1 \ldots x_T\right)'\)</span> and <span class="math inline">\(y = \left(y_1, \ldots, y_T\right)'\)</span>. A closed-form solution for the resulting regression coefficient vector <span class="math inline">\(\beta^\text{ridge}\)</span> exists: <span id="eq-ridge"><span class="math display">\[\hat{\beta}^\text{ridge} = \left(X'X + \lambda I\right)^{-1}X'y,
\tag{5}\]</span></span> where <span class="math inline">\(I\)</span> is the identity matrix of dimension <span class="math inline">\(K\)</span>. A couple of observations are worth noting: <span class="math inline">\(\hat\beta^\text{ridge} = \hat\beta^\text{ols}\)</span> for <span class="math inline">\(\lambda = 0\)</span> and <span class="math inline">\(\hat\beta^\text{ridge} \rightarrow 0\)</span> for <span class="math inline">\(\lambda\rightarrow \infty\)</span>. Also for <span class="math inline">\(\lambda &gt; 0\)</span>, <span class="math inline">\(\left(X'X + \lambda I\right)\)</span> is non-singular even if <span class="math inline">\(X'X\)</span> is which means that <span class="math inline">\(\hat\beta^\text{ridge}\)</span> exists even if <span class="math inline">\(\hat\beta\)</span> is not defined. However, note also that the Ridge estimator requires careful choice of the hyperparameter <span class="math inline">\(\lambda\)</span> which controls the <em>amount of regularization</em>: a larger value of <span class="math inline">\(\lambda\)</span> implies <em>shrinkage</em> of the regression coefficient toward 0; a smaller value of <span class="math inline">\(\lambda\)</span> reduces the bias of the resulting estimator.</p>
<div class="calloutnote">
<p>Note that <span class="math inline">\(X\)</span> usually contains an intercept column with ones. As a general rule, the associated intercept coefficient is not penalized. In practice, this often implies that <span class="math inline">\(y\)</span> is simply demeaned before computing <span class="math inline">\(\hat\beta^\text{ridge}\)</span>.</p>
</div>
<p>What about the statistical properties of the Ridge estimator? First, the bad news is that <span class="math inline">\(\hat\beta^\text{ridge}\)</span> is a biased estimator of <span class="math inline">\(\beta\)</span>. However, the good news is that (under homoscedastic error terms) the variance of the Ridge estimator is guaranteed to be <em>smaller</em> than the variance of the OLS estimator. We encourage you to verify these two statements in the Exercises. As a result, we face a trade-off: The Ridge regression sacrifices some unbiasedness to achieve a smaller variance than the OLS estimator.</p>
</section>
<section id="lasso" class="level3">
<h3 class="anchored" data-anchor-id="lasso">Lasso</h3>
<p></p>
<p>An alternative to Ridge regression is the Lasso (<em>l</em>east <em>a</em>bsolute <em>s</em>hrinkage and <em>s</em>election <em>o</em>perator). Similar to Ridge regression, the Lasso <span class="citation" data-cites="Tibshirani1996">(<a href="#ref-Tibshirani1996" role="doc-biblioref">Tibshirani 1996</a>)</span> is a penalized and biased estimator. The main difference to Ridge regression is that Lasso does not only <em>shrink</em> coefficients but effectively selects variables by setting coefficients for <em>irrelevant</em> variables to zero. Lasso implements a <span class="math inline">\(L_1\)</span> penalization on the parameters such that: <span id="eq-lasso"><span class="math display">\[\hat\beta^\text{Lasso} = \arg\min_\beta \left(Y - X\beta\right)'\left(Y - X\beta\right)\text{ s.t. } \sum\limits_{k=1}^K|\beta_k| &lt; c(\lambda). \tag{6}\]</span></span> There is no closed-form solution for <span class="math inline">\(\hat\beta^\text{Lasso}\)</span> in the above maximization problem, but efficient algorithms exist (e.g., the <code>glmnet</code> package for R and Python). Like for Ridge regression, the hyperparameter <span class="math inline">\(\lambda\)</span> has to be specified beforehand.</p>
<p>The corresponding Lagrangian reads as follows <span id="eq-lasso-lagrangian-initial"><span class="math display">\[\begin{aligned}\hat\beta_\lambda^\text{Lasso} = \arg\min_\beta \left(Y - X\beta\right)'\left(Y - X\beta\right) + \lambda\sum\limits_{k=1}^K|\beta_k|.\end{aligned} \tag{7}\]</span></span></p>
</section>
<section id="elastic-net" class="level3">
<h3 class="anchored" data-anchor-id="elastic-net">Elastic Net</h3>
<p>The Elastic Net <span class="citation" data-cites="Zou2005">(<a href="#ref-Zou2005" role="doc-biblioref">Zou and Hastie 2005</a>)</span> combines <span class="math inline">\(L_1\)</span> with <span class="math inline">\(L_2\)</span> penalization and encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. In terms of the Lagrangian, this more general framework considers the following optimization problem: <span id="eq-elastic-net"><span class="math display">\[\hat\beta^\text{EN} = \arg\min_\beta \left(Y - X\beta\right)'\left(Y - X\beta\right) + \lambda(1-\rho)\sum\limits_{k=1}^K|\beta_k| +\frac{1}{2}\lambda\rho\sum\limits_{k=1}^K\beta_k^2 \tag{8}\]</span></span> Now, we have to choose two hyperparameters: the <em>shrinkage</em> factor <span class="math inline">\(\lambda\)</span> and the <em>weighting parameter</em> <span class="math inline">\(\rho\)</span>. The Elastic Net resembles Lasso for <span class="math inline">\(\rho = 0\)</span> and Ridge regression for <span class="math inline">\(\rho = 1\)</span>. While the <code>glmnet</code> package provides efficient algorithms to compute the coefficients of penalized regressions, it is a good exercise to implement Ridge and Lasso estimation on your own before you use the <code>scikit-learn</code> back-end.</p>
</section>
</section>
<section id="python-packages" class="level2">
<h2 class="anchored" data-anchor-id="python-packages">Python Packages</h2>
<p>To get started, we load the required packages and data. The main focus is on the workflow behind the <code>scikit-learn</code> <span class="citation" data-cites="scikit-learn">(<a href="#ref-scikit-learn" role="doc-biblioref">Pedregosa et al. 2011</a>)</span> package collection.</p>
<div id="acaf1f35" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sqlite3</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine <span class="im">import</span> <span class="op">*</span> </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mizani.formatters <span class="im">import</span> percent_format, date_format</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mizani.breaks <span class="im">import</span> date_breaks</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> product</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> (</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  train_test_split, GridSearchCV, TimeSeriesSplit, cross_val_score</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> ElasticNet, Lasso, Ridge</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="data-preparation" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation">Data Preparation</h2>
<p>In this analysis, we use four different data sources that we load from our SQLite database introduced in <a href="../python/accessing-and-managing-financial-data.html">Accessing and Managing Financial Data</a>. We start with two different sets of factor portfolio returns which have been suggested as representing practical risk factor exposure and thus should be relevant when it comes to asset pricing applications.</p>
<ul>
<li>The standard workhorse: monthly Fama-French 3 factor returns (market, small-minus-big, and high-minus-low book-to-market valuation sorts) defined in <span class="citation" data-cites="Fama1992">Fama and French (<a href="#ref-Fama1992" role="doc-biblioref">1992</a>)</span> and <span class="citation" data-cites="Fama1993">Fama and French (<a href="#ref-Fama1993" role="doc-biblioref">1993</a>)</span>.</li>
<li>Monthly q-factor returns from <span class="citation" data-cites="Hou2015">Hou, Xue, and Zhang (<a href="#ref-Hou2015" role="doc-biblioref">2014</a>)</span>. The factors contain the size factor, the investment factor, the return-on-equity factor, and the expected growth factor.</li>
</ul>
<p>Next, we include macroeconomic predictors which may predict the general stock market economy. Macroeconomic variables effectively serve as conditioning information such that their inclusion hints at the relevance of conditional models instead of unconditional asset pricing. We refer the interested reader to <span class="citation" data-cites="Cochrane2009">Cochrane (<a href="#ref-Cochrane2009" role="doc-biblioref">2009</a>)</span> on the role of conditioning information.</p>
<ul>
<li>Our set of macroeconomic predictors comes from <span class="citation" data-cites="Goyal2008">Welch and Goyal (<a href="#ref-Goyal2008" role="doc-biblioref">2008</a>)</span>. The data has been updated by the authors until 2021 and contains monthly variables that have been suggested as good predictors for the equity premium. Some of the variables are the dividend price ratio, earnings price ratio, stock variance, net equity expansion, treasury bill rate, and inflation.</li>
</ul>
<p>Finally, we need a set of <em>test assets</em>. The aim is to understand which of the plenty factors and macroeconomic variable combinations prove helpful in explaining our test assets’ cross-section of returns. In line with many existing papers, we use monthly portfolio returns from ten different industries according to the definition from <a href="https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/det_10_ind_port.html">Kenneth French’s homepage</a> as test assets.</p>
<div id="b0cb1173" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>tidy_finance <span class="op">=</span> sqlite3.<span class="ex">connect</span>(database<span class="op">=</span><span class="st">"data/tidy_finance_python.sqlite"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>factors_ff3_monthly <span class="op">=</span> (pd.read_sql_query(</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>     sql<span class="op">=</span><span class="st">"SELECT * FROM factors_ff3_monthly"</span>,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>     con<span class="op">=</span>tidy_finance,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>     parse_dates<span class="op">=</span>{<span class="st">"date"</span>})</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  .add_prefix(<span class="st">"factor_ff_"</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>factors_q_monthly <span class="op">=</span> (pd.read_sql_query(</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    sql<span class="op">=</span><span class="st">"SELECT * FROM factors_q_monthly"</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    con<span class="op">=</span>tidy_finance,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    parse_dates<span class="op">=</span>{<span class="st">"date"</span>})</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  .add_prefix(<span class="st">"factor_q_"</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>macro_predictors <span class="op">=</span> (pd.read_sql_query(</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    sql<span class="op">=</span><span class="st">"SELECT * FROM macro_predictors"</span>,</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    con<span class="op">=</span>tidy_finance,</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    parse_dates<span class="op">=</span>{<span class="st">"date"</span>})</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a> .add_prefix(<span class="st">"macro_"</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>industries_ff_monthly <span class="op">=</span> (pd.read_sql_query(</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    sql<span class="op">=</span><span class="st">"SELECT * FROM industries_ff_monthly"</span>,</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    con<span class="op">=</span>tidy_finance,</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    parse_dates<span class="op">=</span>{<span class="st">"date"</span>})</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>  .melt(id_vars<span class="op">=</span><span class="st">"date"</span>, var_name<span class="op">=</span><span class="st">"industry"</span>, value_name<span class="op">=</span><span class="st">"ret"</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We combine all the monthly observations into one dataframe.</p>
<div id="672c83ef" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> (industries_ff_monthly</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  .merge(factors_ff3_monthly, </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>         how<span class="op">=</span><span class="st">"left"</span>, left_on<span class="op">=</span><span class="st">"date"</span>, right_on<span class="op">=</span><span class="st">"factor_ff_date"</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  .merge(factors_q_monthly, </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>         how<span class="op">=</span><span class="st">"left"</span>, left_on<span class="op">=</span><span class="st">"date"</span>, right_on<span class="op">=</span><span class="st">"factor_q_date"</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  .merge(macro_predictors, </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>         how<span class="op">=</span><span class="st">"left"</span>, left_on<span class="op">=</span><span class="st">"date"</span>, right_on<span class="op">=</span><span class="st">"macro_date"</span>) </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  .assign(ret_excess<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">"ret"</span>] <span class="op">-</span> x[<span class="st">"factor_ff_rf"</span>]) </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  .drop(columns<span class="op">=</span>[<span class="st">"ret"</span>, <span class="st">"factor_ff_date"</span>, <span class="st">"factor_q_date"</span>, <span class="st">"macro_date"</span>])</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  .dropna()</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Our data contains 23 columns of regressors with the 13 macro-variables and 9 factor returns for each month. <a href="#fig-1401" class="quarto-xref">Figure&nbsp;1</a> provides summary statistics for the 10 monthly industry excess returns in percent. One can see that the dispersion in the excess returns varies widely across industries. </p>
<div id="cell-fig-1401" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>data_plot <span class="op">=</span> (ggplot(data, </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  aes(x<span class="op">=</span><span class="st">"industry"</span>, y<span class="op">=</span><span class="st">"ret_excess"</span>)) <span class="op">+</span> </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  geom_boxplot() <span class="op">+</span> </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  coord_flip() <span class="op">+</span> </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  labs(x<span class="op">=</span><span class="st">""</span>, y<span class="op">=</span><span class="st">""</span>, </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>       title<span class="op">=</span><span class="st">"Excess return distributions by industry in percent"</span>) <span class="op">+</span> </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>   scale_y_continuous(labels<span class="op">=</span>percent_format())</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>data_plot.draw()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div id="fig-1401" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Title: Excess return distributions by industry in percent. The figure shows boxplots that visualize the industry's excess return distribution. All industry returns are centered around zero and exhibit substantial outliers in the magnitude of 20 percent on a monthly basis." data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1401-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="factor-selection-via-machine-learning_files/figure-html/fig-1401-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: The box plots show the monthly dispersion of returns for 10 different industries."><img src="factor-selection-via-machine-learning_files/figure-html/fig-1401-output-1.png" data-fig-pos="htb" alt="Title: Excess return distributions by industry in percent. The figure shows boxplots that visualize the industry's excess return distribution. All industry returns are centered around zero and exhibit substantial outliers in the magnitude of 20 percent on a monthly basis." width="647" height="407" class="figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1401-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The box plots show the monthly dispersion of returns for 10 different industries.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="machine-learning-workflow" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-workflow">Machine Learning Workflow</h2>
<p>To illustrate penalized linear regressions, we employ the <code>scikit-learn</code> collection of packages for modeling and ML. Using the ideas of Ridge and Lasso regressions, the following example guides you through (i) pre-processing the data (data split and variable mutation), (ii) building models, (iii) fitting models, and (iv) tuning models to create the “best” possible predictions.</p>
<section id="pre-process-data" class="level3">
<h3 class="anchored" data-anchor-id="pre-process-data">Pre-process data</h3>
<p>We want to explain excess returns with all available predictors. The regression equation thus takes the form <span id="eq-factor-model"><span class="math display">\[r_{t} = \alpha_0 + \left(\tilde f_t \otimes \tilde z_t\right)B + \varepsilon_t  \tag{9}\]</span></span> where <span class="math inline">\(r_t\)</span> is the vector of industry excess returns at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\otimes\)</span> denotes the Kronecker product and <span class="math inline">\(\tilde f_t\)</span> and <span class="math inline">\(\tilde z_t\)</span> are the (standardized) vectors of factor portfolio returns and macroeconomic variables.</p>
<p>We hence perform the following pre-processing steps:</p>
<ul>
<li>We exclude the column <em>month</em> from the analysis</li>
<li>We include all interaction terms between factors and macroeconomic predictors</li>
<li>We demean and scale each regressor such that the standard deviation is one</li>
</ul>
<p>Scaling is often necessary in machine learning applications, especially when combining variables of different magnitudes or units, or when using algorithms sensitive to feature scales (e.g., gradient descent-based algorithms). We use <code>ColumnTransformer()</code> to scale all regressors using <code>StandardScaler()</code>. The <code>remainder="drop"</code> ensures that only the specified columns are retained in the output, and others are dropped. The option <code>verbose_feature_names_out=False</code> ensures that the output feature names remain unchanged. Also note that we use the <code>zip()</code> function to pair each element from <code>column_names</code> with its corresponding list of values from <code>new_column_values</code>, creating tuples, and then convert these tuples into a dictionary using <code>dict()</code> from which we create a dataframe.</p>
<div id="452fc83d" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>macro_variables <span class="op">=</span> data.<span class="bu">filter</span>(like<span class="op">=</span><span class="st">"macro"</span>).columns</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>factor_variables <span class="op">=</span> data.<span class="bu">filter</span>(like<span class="op">=</span><span class="st">"factor"</span>).columns</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>column_combinations <span class="op">=</span> <span class="bu">list</span>(product(macro_variables, factor_variables))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>new_column_values <span class="op">=</span> []</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> macro_column, factor_column <span class="kw">in</span> column_combinations:</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    new_column_values.append(data[macro_column] <span class="op">*</span> data[factor_column])</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>column_names <span class="op">=</span> [<span class="st">" x "</span>.join(t) <span class="cf">for</span> t <span class="kw">in</span> column_combinations]</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>new_columns <span class="op">=</span> pd.DataFrame(<span class="bu">dict</span>(<span class="bu">zip</span>(column_names, new_column_values)))</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.concat([data, new_columns], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> ColumnTransformer(</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>  transformers<span class="op">=</span>[</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"scale"</span>, StandardScaler(), </span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    [col <span class="cf">for</span> col <span class="kw">in</span> data.columns </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> col <span class="kw">not</span> <span class="kw">in</span> [<span class="st">"ret_excess"</span>, <span class="st">"date"</span>, <span class="st">"industry"</span>]])</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>  ],</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>  remainder<span class="op">=</span><span class="st">"drop"</span>,</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>  verbose_feature_names_out<span class="op">=</span><span class="va">False</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="build-a-model" class="level3">
<h3 class="anchored" data-anchor-id="build-a-model">Build a model</h3>
<p> Next, we can build an actual model based on our pre-processed data. In line with the definition above, we estimate regression coefficients of a Lasso regression such that we get</p>
<p><span id="eq-lasso-lagrangian"><span class="math display">\[\begin{aligned}\hat\beta_\lambda^\text{Lasso} = \arg\min_\beta \left(Y - X\beta\right)'\left(Y - X\beta\right) + \lambda\sum\limits_{k=1}^K|\beta_k|.\end{aligned} \tag{10}\]</span></span> In the application at hand, <span class="math inline">\(X\)</span> contains 117 columns with all possible interactions between factor returns and macroeconomic variables. We want to emphasize that the workflow for <em>any</em> model is very similar, irrespective of the specific model. As you will see further below, it is straightforward to fit Ridge regression coefficients and, later, Neural networks or Random forests with similar code. For now, we start with the linear regression model with an arbitrarily chosen value for the penalty factor <span class="math inline">\(\lambda\)</span> (denoted as <code>alpha=0.007</code> in the code below). In the setup below, <code>l1_ratio</code> denotes the value of <span class="math inline">\(1-\rho\)</span>, hence setting <code>l1_ratio=1</code> implies the Lasso.</p>
<div id="26d7109f" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>lm_model <span class="op">=</span> ElasticNet(</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  alpha<span class="op">=</span><span class="fl">0.007</span>,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  l1_ratio<span class="op">=</span><span class="dv">1</span>, </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  max_iter<span class="op">=</span><span class="dv">5000</span>, </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  fit_intercept<span class="op">=</span><span class="va">False</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>)  </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>lm_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  (<span class="st">"preprocessor"</span>, preprocessor),</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  (<span class="st">"regressor"</span>, lm_model)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>That’s it - we are done! The object <code>lm_model_pipeline</code> contains the definition of our model with all required information, in particular the pre-processing steps and the regression model.</p>
</section>
<section id="fit-a-model" class="level3">
<h3 class="anchored" data-anchor-id="fit-a-model">Fit a model</h3>
<p>With the pipeline from above, we are ready to fit it to the data. Typically, we use training data to fit the model. The training data is pre-processed according to our recipe steps, and the Lasso regression coefficients are computed. For illustrative purposes, we focus on the manufacturing industry for now.</p>
<div id="28ef1b50" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>data_manufacturing <span class="op">=</span> data.query(<span class="st">"industry == 'manuf'"</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>training_date <span class="op">=</span> <span class="st">"2011-12-01"</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>data_manufacturing_training <span class="op">=</span> (data_manufacturing</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  .query(<span class="ss">f"date&lt;'</span><span class="sc">{</span>training_date<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>lm_fit <span class="op">=</span> lm_pipeline.fit(</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  data_manufacturing_training, </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  data_manufacturing_training.get(<span class="st">"ret_excess"</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>First, we focus on the in-sample predicted values <span class="math inline">\(\hat{y}_t = x_t\hat\beta^\text{Lasso}.\)</span> <a href="#fig-1402" class="quarto-xref">Figure&nbsp;2</a> illustrates the projections for the <em>entire</em> time series of the manufacturing industry portfolio returns.</p>
<div id="cell-fig-1402" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>predicted_values <span class="op">=</span> (pd.DataFrame({</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Fitted value"</span>: lm_fit.predict(data_manufacturing),</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Realization"</span>: data_manufacturing.get(<span class="st">"ret_excess"</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  .assign(date <span class="op">=</span> data_manufacturing[<span class="st">"date"</span>])</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  .melt(id_vars<span class="op">=</span><span class="st">"date"</span>, var_name<span class="op">=</span><span class="st">"Variable"</span>, value_name<span class="op">=</span><span class="st">"return"</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>predicted_values_plot <span class="op">=</span> (</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  ggplot(predicted_values, </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>         aes(x<span class="op">=</span><span class="st">"date"</span>, y<span class="op">=</span><span class="st">"return"</span>, </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>             color<span class="op">=</span><span class="st">"Variable"</span>, linetype<span class="op">=</span><span class="st">"Variable"</span>)) <span class="op">+</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  annotate(</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"rect"</span>,</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    xmin<span class="op">=</span>data_manufacturing_training[<span class="st">"date"</span>].<span class="bu">max</span>(),</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    xmax<span class="op">=</span>data_manufacturing[<span class="st">"date"</span>].<span class="bu">max</span>(),</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    ymin<span class="op">=-</span>np.inf, ymax<span class="op">=</span>np.inf,</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.25</span>, fill<span class="op">=</span><span class="st">"#808080"</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  ) <span class="op">+</span> </span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  geom_line() <span class="op">+</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>  labs(x<span class="op">=</span><span class="st">""</span>, y<span class="op">=</span><span class="st">""</span>, color<span class="op">=</span><span class="st">""</span>, linetype<span class="op">=</span><span class="st">""</span>,</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>       title<span class="op">=</span><span class="st">"Monthly realized and fitted manufacturing risk premia"</span>) <span class="op">+</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>  scale_x_datetime(breaks<span class="op">=</span>date_breaks(<span class="st">"5 years"</span>), </span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>                   labels<span class="op">=</span>date_format(<span class="st">"%Y"</span>)) <span class="op">+</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>  scale_y_continuous(labels<span class="op">=</span>percent_format())</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>predicted_values_plot.draw()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div id="fig-1402" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Title: Monthly realized and fitted manufacturing industry risk premium. The figure shows the time series of realized and predicted manufacturing industry risk premiums. The figure seems to indicate that the predictions capture most of the return dynamics." data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1402-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="factor-selection-via-machine-learning_files/figure-html/fig-1402-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: The figure shows monthly realized and fitted manufacturing industry risk premium. The grey area corresponds to the out of sample period."><img src="factor-selection-via-machine-learning_files/figure-html/fig-1402-output-1.png" data-fig-pos="htb" alt="Title: Monthly realized and fitted manufacturing industry risk premium. The figure shows the time series of realized and predicted manufacturing industry risk premiums. The figure seems to indicate that the predictions capture most of the return dynamics." width="647" height="407" class="figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1402-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The figure shows monthly realized and fitted manufacturing industry risk premium. The grey area corresponds to the out of sample period.
</figcaption>
</figure>
</div>
</div>
</div>
<p>What do the estimated coefficients look like? To analyze these values, it is worth computing the coefficients <span class="math inline">\(\hat\beta^\text{Lasso}\)</span> directly. The code below estimates the coefficients for the Lasso and Ridge regression for the processed training data sample for a grid of different <span class="math inline">\(\lambda\)</span>’s.</p>
<div id="0eeaa901" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> preprocessor.fit_transform(data_manufacturing)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data_manufacturing[<span class="st">"ret_excess"</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">100</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>coefficients_lasso <span class="op">=</span> []</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> a <span class="kw">in</span> alphas:</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    lasso <span class="op">=</span> Lasso(alpha<span class="op">=</span>a, fit_intercept<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    coefficients_lasso.append(lasso.fit(x, y).coef_)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>coefficients_lasso <span class="op">=</span> (pd.DataFrame(coefficients_lasso)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  .assign(alpha<span class="op">=</span>alphas, model<span class="op">=</span><span class="st">"Lasso"</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  .melt(id_vars<span class="op">=</span>[<span class="st">"alpha"</span>, <span class="st">"model"</span>])</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>coefficients_ridge <span class="op">=</span> []</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> a <span class="kw">in</span> alphas:</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    ridge <span class="op">=</span> Ridge(alpha<span class="op">=</span>a, fit_intercept<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    coefficients_ridge.append(ridge.fit(x, y).coef_)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>coefficients_ridge <span class="op">=</span> (pd.DataFrame(coefficients_ridge)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>  .assign(alpha<span class="op">=</span>alphas, model<span class="op">=</span><span class="st">"Ridge"</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>  .melt(id_vars<span class="op">=</span>[<span class="st">"alpha"</span>, <span class="st">"model"</span>])</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The dataframes <code>lasso_coefficients</code> and <code>ridge_coefficients</code> contain an entire sequence of estimated coefficients for multiple values of the penalty factor <span class="math inline">\(\lambda\)</span>. <a href="#fig-1403" class="quarto-xref">Figure&nbsp;3</a> illustrates the trajectories of the regression coefficients as a function of the penalty factor. Both Lasso and Ridge coefficients converge to zero as the penalty factor increases.</p>
<div id="cell-fig-1403" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>coefficients_plot <span class="op">=</span> (</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  ggplot(pd.concat([coefficients_lasso, coefficients_ridge]), </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>         aes(x<span class="op">=</span><span class="st">"alpha"</span>, y<span class="op">=</span><span class="st">"value"</span>, color<span class="op">=</span><span class="st">"variable"</span>)) <span class="op">+</span> </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  geom_line()  <span class="op">+</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  facet_wrap(<span class="st">"model"</span>) <span class="op">+</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  labs(x<span class="op">=</span><span class="st">"Penalty factor (lambda)"</span>, y<span class="op">=</span><span class="st">""</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>       title<span class="op">=</span><span class="st">"Estimated coefficient paths for different penalty factors"</span>) <span class="op">+</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  scale_x_log10() <span class="op">+</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  theme(legend_position<span class="op">=</span><span class="st">"none"</span>))</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>coefficients_plot.draw()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div id="fig-1403" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Title: Estimated coefficient paths for different penalty factors. The figure shows how estimated lasso and ridge coefficients tend to zero for a higher penalty parameter. Ridge trace is smooth, and Lasso exhibits non-linear behavior." data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1403-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="factor-selection-via-machine-learning_files/figure-html/fig-1403-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: The figure shows estimated coefficient paths for different penalty factors. The penalty parameters are chosen iteratively to resemble the path from no penalization to a model that excludes all variables."><img src="factor-selection-via-machine-learning_files/figure-html/fig-1403-output-1.png" data-fig-pos="htb" alt="Title: Estimated coefficient paths for different penalty factors. The figure shows how estimated lasso and ridge coefficients tend to zero for a higher penalty parameter. Ridge trace is smooth, and Lasso exhibits non-linear behavior." width="647" height="407" class="figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1403-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: The figure shows estimated coefficient paths for different penalty factors. The penalty parameters are chosen iteratively to resemble the path from no penalization to a model that excludes all variables.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="tune-a-model" class="level3">
<h3 class="anchored" data-anchor-id="tune-a-model">Tune a model</h3>
<p>To compute <span class="math inline">\(\hat\beta_\lambda^\text{Lasso}\)</span> , we simply imposed an arbitrary value for the penalty hyperparameter <span class="math inline">\(\lambda\)</span>. Model tuning is the process of optimally selecting such hyperparameters through <em>cross-validation</em>.</p>
<p>The goal for choosing <span class="math inline">\(\lambda\)</span> (or any other hyperparameter, e.g., <span class="math inline">\(\rho\)</span> for the Elastic Net) is to find a way to produce predictors <span class="math inline">\(\hat{Y}\)</span> for an outcome <span class="math inline">\(Y\)</span> that minimizes the mean squared prediction error <span class="math inline">\(\text{MSPE} = E\left( \frac{1}{T}\sum_{t=1}^T (\hat{y}_t - y_t)^2 \right)\)</span>. Unfortunately, the MSPE is not directly observable. We can only compute an estimate because our data is random and because we do not observe the entire population.</p>
<p>Obviously, if we train an algorithm on the same data that we use to compute the error, our estimate <span class="math inline">\(\text{MSPE}\)</span> would indicate way better predictive accuracy than what we can expect in real out-of-sample data. The result is called overfitting.</p>
<p>Cross-validation is a technique that allows us to alleviate this problem. We approximate the true MSPE as the average of many MSPE obtained by creating predictions for <span class="math inline">\(K\)</span> new random samples of the data, none of them used to train the algorithm <span class="math inline">\(\frac{1}{K} \sum_{k=1}^K \frac{1}{T}\sum_{t=1}^T \left(\hat{y}_t^k - y_t^k\right)^2\)</span>. In practice, this is done by carving out a piece of our data and pretending it is an independent sample. We again divide the data into a training set and a test set. The MSPE on the test set is our measure for actual predictive ability, while we use the training set to fit models with the aim to find the <em>optimal</em> hyperparameter values. To do so, we further divide our training sample into (several) subsets, fit our model for a grid of potential hyperparameter values (e.g., <span class="math inline">\(\lambda\)</span>), and evaluate the predictive accuracy on an <em>independent</em> sample. This works as follows:</p>
<ol type="1">
<li>Specify a grid of hyperparameters</li>
<li>Obtain predictors <span class="math inline">\(\hat{y}_i(\lambda)\)</span> to denote the predictors for the used parameters <span class="math inline">\(\lambda\)</span></li>
<li>Compute <span id="eq-mspe"><span class="math display">\[
\text{MSPE}(\lambda) = \frac{1}{K} \sum_{k=1}^K \frac{1}{T}\sum_{t=1}^T \left(\hat{y}_t^k(\lambda) - y_t^k\right)^2 .
\tag{11}\]</span></span> With K-fold cross-validation, we do this computation <span class="math inline">\(K\)</span> times. Simply pick a validation set with <span class="math inline">\(M=T/K\)</span> observations at random and think of these as random samples <span class="math inline">\(y_1^k, \dots, y_{\tilde{T}}^k\)</span>, with <span class="math inline">\(k=1\)</span>.</li>
</ol>
<p>How should you pick <span class="math inline">\(K\)</span>? Large values of <span class="math inline">\(K\)</span> are preferable because the training data better imitates the original data. However, larger values of <span class="math inline">\(K\)</span> will have much higher computation time. <code>scikit-learn</code> provides all required tools to conduct <span class="math inline">\(K\)</span>-fold cross-validation. We just have to update our model specification. In our case, we specify the penalty factor <span class="math inline">\(\lambda\)</span> as well as the mixing factor <span class="math inline">\(\rho\)</span> as <em>free</em> parameters.</p>
<p>For our sample, we consider a time-series cross-validation sample. This means that we tune our models with 20 samples of length five years with a validation period of four years. For a grid of possible hyperparameters, we then fit the model for each fold and evaluate <span class="math inline">\(\hat{\text{MSPE}}\)</span> in the corresponding validation set. Finally, we select the model specification with the lowest MSPE in the validation set. First, we define the cross-validation folds based on our training data only.</p>
<p>Then, we evaluate the performance for a grid of different penalty values. <code>scikit-learn</code> provides functionalities to construct a suitable grid of hyperparameters with <code>GridSearchCV()</code>. The code chunk below creates a <span class="math inline">\(10 \times 3\)</span> hyperparameters grid. Then, the method <code>fit()</code> evaluates all the models for each fold.</p>
<div id="db7e6b6b" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>initial_years <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>assessment_months <span class="op">=</span> <span class="dv">48</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>n_splits <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(data_manufacturing)<span class="op">/</span>assessment_months) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>length_of_year <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">2</span>, <span class="dv">100</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>data_folds <span class="op">=</span> TimeSeriesSplit(</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  n_splits<span class="op">=</span>n_splits, </span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  test_size<span class="op">=</span>assessment_months, </span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  max_train_size<span class="op">=</span>initial_years <span class="op">*</span> length_of_year</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  <span class="st">"regressor__alpha"</span>: alphas,</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>  <span class="st">"regressor__l1_ratio"</span>: (<span class="fl">0.0</span>, <span class="fl">0.5</span>, <span class="dv">1</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>finder <span class="op">=</span> GridSearchCV(</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>  lm_pipeline,</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  param_grid<span class="op">=</span>params,</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>  scoring<span class="op">=</span><span class="st">"neg_root_mean_squared_error"</span>,</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>  cv<span class="op">=</span>data_folds</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>finder <span class="op">=</span> finder.fit(</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>  data_manufacturing, data_manufacturing.get(<span class="st">"ret_excess"</span>)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After the tuning process, we collect the evaluation metrics (the root mean-squared error in our example) to identify the <em>optimal</em> model. <a href="#fig-1404" class="quarto-xref">Figure&nbsp;4</a> illustrates the average validation set’s root mean-squared error for each value of <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\rho\)</span>.</p>
<div id="cell-fig-1404" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>validation <span class="op">=</span> (pd.DataFrame(finder.cv_results_)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  .assign(</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    mspe<span class="op">=</span><span class="kw">lambda</span> x: <span class="op">-</span>x[<span class="st">"mean_test_score"</span>],</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    param_regressor__alpha<span class="op">=</span><span class="kw">lambda</span> x: pd.to_numeric(</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>      x[<span class="st">"param_regressor__alpha"</span>], errors<span class="op">=</span><span class="st">"coerce"</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>validation_plot <span class="op">=</span> (ggplot(validation, </span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  aes(x<span class="op">=</span><span class="st">"param_regressor__alpha"</span>, y<span class="op">=</span><span class="st">"mspe"</span>, </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>      color<span class="op">=</span><span class="st">"param_regressor__l1_ratio"</span>,</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>      shape<span class="op">=</span><span class="st">"param_regressor__l1_ratio"</span>,</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>      group<span class="op">=</span><span class="st">"param_regressor__l1_ratio"</span>)) <span class="op">+</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  geom_point() <span class="op">+</span> </span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  geom_line() <span class="op">+</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  labs(x <span class="op">=</span><span class="st">"Penalty factor (lambda)"</span>, y<span class="op">=</span><span class="st">"Root MSPE"</span>, </span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>       title<span class="op">=</span><span class="st">"Root MSPE for different penalty factors"</span>,</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>       color<span class="op">=</span><span class="st">"Proportion of Lasso Penalty"</span>,</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>       shape<span class="op">=</span><span class="st">"Proportion of Lasso Penalty"</span>) <span class="op">+</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>  scale_x_log10() <span class="op">+</span> </span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>  guides(linetype<span class="op">=</span><span class="st">"none"</span>)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>validation_plot.draw()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div id="fig-1404" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Title: Root MSPE for different penalty factors. The figure shows that more regularization does not affect the selected models in a meaningful fashion. At some point, the Elastic Net prediction error drops, which indicates the selected model. MSPE increases again for high penalization values." data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1404-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="factor-selection-via-machine-learning_files/figure-html/fig-1404-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: The figure shows root MSPE for different penalty factors. Evaluation of manufacturing excess returns for different penalty factors (lambda) and proportions of Lasso penalty (rho). 1.0 indicates Lasso, 0.5 indicates Elastic Net, and 0.0 indicates Ridge."><img src="factor-selection-via-machine-learning_files/figure-html/fig-1404-output-1.png" data-fig-pos="htb" alt="Title: Root MSPE for different penalty factors. The figure shows that more regularization does not affect the selected models in a meaningful fashion. At some point, the Elastic Net prediction error drops, which indicates the selected model. MSPE increases again for high penalization values." width="647" height="407" class="figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1404-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: The figure shows root MSPE for different penalty factors. Evaluation of manufacturing excess returns for different penalty factors (lambda) and proportions of Lasso penalty (rho). 1.0 indicates Lasso, 0.5 indicates Elastic Net, and 0.0 indicates Ridge.
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-1404" class="quarto-xref">Figure&nbsp;4</a> shows that the MSPE drops faster for Lasso and Elastic Net compared to Ridge regressions as penalty factor increases. However, for higher penalty factors, the MSPE for Ridge regressions dips below the others, which both slightly increase again above a certain threshold. Recall that the larger the regularization, the more restricted the model becomes. The best performing model yields a penalty parameter (<code>alpha</code>) of 0.0043 and a mixture factor (<span class="math inline">\(\rho\)</span>) of 0.5.</p>
</section>
<section id="full-workflow" class="level3">
<h3 class="anchored" data-anchor-id="full-workflow">Full workflow</h3>
<p>Our starting point was the question: Which factors determine industry returns? While <span class="citation" data-cites="Avramov2022b">Avramov et al. (<a href="#ref-Avramov2022b" role="doc-biblioref">2023</a>)</span> provide a Bayesian analysis related to the research question above, we choose a simplified approach: To illustrate the entire workflow, we now run the penalized regressions for all ten industries. We want to identify relevant variables by fitting Lasso models for each industry returns time series. More specifically, we perform cross-validation for each industry to identify the optimal penalty factor <span class="math inline">\(\lambda\)</span>.</p>
<p>First, we define the Lasso model with one tuning parameter.</p>
<div id="f94ec8fa" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>lm_model <span class="op">=</span> Lasso(fit_intercept<span class="op">=</span><span class="va">False</span>, max_iter<span class="op">=</span><span class="dv">5000</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {<span class="st">"regressor__alpha"</span>: alphas}</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>lm_pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  (<span class="st">"preprocessor"</span>, preprocessor),</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  (<span class="st">"regressor"</span>, lm_model)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following task can be easily parallelized to reduce computing time, but we use a simple loop for ease of exposition.</p>
<div id="07ee38a5" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>all_industries <span class="op">=</span> data[<span class="st">"industry"</span>].drop_duplicates()</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> industry <span class="kw">in</span> all_industries:</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(industry)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  finder <span class="op">=</span> GridSearchCV(</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    lm_pipeline,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    param_grid<span class="op">=</span>params,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">"neg_mean_squared_error"</span>,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span>data_folds</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>  finder <span class="op">=</span> finder.fit(</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    data.query(<span class="st">"industry == @industry"</span>),</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    data.query(<span class="st">"industry == @industry"</span>).get(<span class="st">"ret_excess"</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>  results.append(</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    pd.DataFrame(finder.best_estimator_.named_steps.regressor.coef_ <span class="op">!=</span> <span class="dv">0</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>selected_factors <span class="op">=</span> (</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>  pd.DataFrame(</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    lm_pipeline[:<span class="op">-</span><span class="dv">1</span>].get_feature_names_out(),</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">"variable"</span>]</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>  .assign(variable <span class="op">=</span> <span class="kw">lambda</span> x: (</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    x[<span class="st">"variable"</span>].<span class="bu">str</span>.replace(<span class="st">"factor_|ff_|q_|macro_"</span>,<span class="st">""</span>))</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>  .assign(<span class="op">**</span><span class="bu">dict</span>(<span class="bu">zip</span>(all_industries, results)))</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>  .melt(id_vars<span class="op">=</span><span class="st">"variable"</span>, var_name <span class="op">=</span><span class="st">"industry"</span>)</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>  .query(<span class="st">"value == True"</span>)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>What has just happened? In principle, exactly the same as before but instead of computing the Lasso coefficients for one industry, we did it for ten sequentially. Now, we just have to do some housekeeping and keep only variables that Lasso does <em>not</em> set to zero. We illustrate the results in a heat map in <a href="#fig-1405" class="quarto-xref">Figure&nbsp;5</a>.</p>
<div id="cell-fig-1405" class="cell" data-fig-height="7" data-execution_count="17">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>selected_factors_plot <span class="op">=</span> (</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  ggplot(selected_factors, </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>         aes(x<span class="op">=</span><span class="st">"variable"</span>, y<span class="op">=</span><span class="st">"industry"</span>)) <span class="op">+</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  geom_tile() <span class="op">+</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  labs(x<span class="op">=</span><span class="st">""</span>, y<span class="op">=</span><span class="st">""</span>, </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>       title<span class="op">=</span><span class="st">"Selected variables for different industries"</span>) <span class="op">+</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  coord_flip() <span class="op">+</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  scale_x_discrete(limits<span class="op">=</span><span class="bu">reversed</span>) <span class="op">+</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  theme(axis_text_x<span class="op">=</span>element_text(rotation<span class="op">=</span><span class="dv">70</span>, hjust<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>        figure_size<span class="op">=</span>(<span class="fl">6.4</span>, <span class="fl">6.4</span>))</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>selected_factors_plot.draw()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<div id="fig-1405" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Title: Selected variables for different industries. The figure shows which factors and macroeconomic predictors the Lasso model selected for the different industries. In general, there are not many selected variables. The market excess return is selected across all industries except for utilities." data-fig-pos="htb">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1405-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="factor-selection-via-machine-learning_files/figure-html/fig-1405-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: The figure shows selected variables for different industries. Dark areas indicate that the estimated Lasso regression coefficient is not set to zero. White fields show which variables get assigned a value of exactly zero."><img src="factor-selection-via-machine-learning_files/figure-html/fig-1405-output-1.png" data-fig-pos="htb" alt="Title: Selected variables for different industries. The figure shows which factors and macroeconomic predictors the Lasso model selected for the different industries. In general, there are not many selected variables. The market excess return is selected across all industries except for utilities." width="647" height="647" class="figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1405-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: The figure shows selected variables for different industries. Dark areas indicate that the estimated Lasso regression coefficient is not set to zero. White fields show which variables get assigned a value of exactly zero.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The heat map in <a href="#fig-1405" class="quarto-xref">Figure&nbsp;5</a> conveys two main insights: first, we see that many factors, macroeconomic variables, and interaction terms are not relevant for explaining the cross-section of returns across the industry portfolios. In fact, only <code>factor_ff_mkt_excess</code> and its interaction with <code>macro_bm</code> a role for several industries. Second, there seems to be quite some heterogeneity across different industries. While barely any variable is selected by Lasso for Utilities, many factors are selected for, e.g., Durable and Manufacturing, but the selected factors do not necessarily coincide. In other words, there seems to be a clear picture that we do not need many factors, but Lasso does not provide a factor that consistently provides pricing abilities across industries.</p>
</section>
</section>
<section id="exercises" class="level2">
<h2 class="anchored" data-anchor-id="exercises">Exercises</h2>
<ol type="1">
<li>Write a function that requires three inputs, namely, <code>y</code> (a <span class="math inline">\(T\)</span> vector), <code>X</code> (a <span class="math inline">\((T \times K)\)</span> matrix), and <code>lambda</code> and then returns the Ridge estimator (a <span class="math inline">\(K\)</span> vector) for a given penalization parameter <span class="math inline">\(\lambda\)</span>. Recall that the intercept should not be penalized. Therefore, your function should indicate whether <span class="math inline">\(X\)</span> contains a vector of ones as the first column, which should be exempt from the <span class="math inline">\(L_2\)</span> penalty.</li>
<li>Compute the <span class="math inline">\(L_2\)</span> norm (<span class="math inline">\(\beta'\beta\)</span>) for the regression coefficients based on the predictive regression from the previous exercise for a range of <span class="math inline">\(\lambda\)</span>’s and illustrate the effect of penalization in a suitable figure.</li>
<li>Now, write a function that requires three inputs, namely, <code>y</code> (a <span class="math inline">\(T\)</span> vector), <code>X</code> (a <span class="math inline">\((T \times K)\)</span> matrix), and <span class="math inline">\(\lambda\)</span> and then returns the Lasso estimator (a <span class="math inline">\(K\)</span> vector) for a given penalization parameter <span class="math inline">\(\lambda\)</span>. Recall that the intercept should not be penalized. Therefore, your function should indicate whether <span class="math inline">\(X\)</span> contains a vector of ones as the first column, which should be exempt from the <span class="math inline">\(L_1\)</span> penalty.</li>
<li>After you understand what Ridge and Lasso regressions are doing, familiarize yourself with the <code>glmnet</code> package’s documentation. It is a thoroughly tested and well-established package that provides efficient code to compute the penalized regression coefficients for Ridge and Lasso and for combinations, commonly called <em>Elastic Nets</em>.</li>
</ol>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Avramov2022b" class="csl-entry" role="listitem">
Avramov, Doron, Si Cheng, Lior Metzker, and Stefan Voigt. 2023. <span>“<span class="nocase">Integrating factor models</span>.”</span> <em><span>The Journal of Finance</span></em> 78 (3): 1593–1646. <a href="https://doi.org/10.1111/jofi.13226">https://doi.org/10.1111/jofi.13226</a>.
</div>
<div id="ref-Cochrane2009" class="csl-entry" role="listitem">
Cochrane, John H. 2009. <em><span class="nocase">Asset pricing (revised edition)</span></em>. Princeton University Press.
</div>
<div id="ref-Cochrane2011" class="csl-entry" role="listitem">
———. 2011. <span>“<span class="nocase">Presidential address: Discount rates</span>.”</span> <em><span>The Journal of Finance</span></em> 66 (4): 1047–1108. <a href="https://doi.org/10.1111/j.1540-6261.2011.01671.x">https://doi.org/10.1111/j.1540-6261.2011.01671.x</a>.
</div>
<div id="ref-DePrado2018" class="csl-entry" role="listitem">
De Prado, Marcos Lopez. 2018. <em><span class="nocase">Advances in financial machine learning</span></em>. John Wiley &amp; Sons. <a href="https://doi.org/10.5555/3217448">https://doi.org/10.5555/3217448</a>.
</div>
<div id="ref-Dixon2020" class="csl-entry" role="listitem">
Dixon, Matthew F., Igor Halperin, and Paul Bilokon. 2020. <em><span class="nocase">Machine learning in finance</span></em>. Springer.
</div>
<div id="ref-Easley2021" class="csl-entry" role="listitem">
Easley, David, Marcos de Prado, Maureen O’Hara, and Zhibai Zhang. 2020. <span>“<span class="nocase">Microstructure in the machine age</span>.”</span> <em><span>Review of Financial Studies</span></em> 34 (7): 3316–63. <a href="https://doi.org/10.1093/rfs/hhaa078">https://doi.org/10.1093/rfs/hhaa078</a>.
</div>
<div id="ref-Fama1992" class="csl-entry" role="listitem">
Fama, Eugene F., and Kenneth R. French. 1992. <span>“<span class="nocase">The cross-section of expected stock returns</span>.”</span> <em><span>The Journal of Finance</span></em> 47 (2): 427–65. <a href="https://doi.org/2329112">https://doi.org/2329112</a>.
</div>
<div id="ref-Fama1993" class="csl-entry" role="listitem">
———. 1993. <span>“<span class="nocase">Common risk factors in the returns on stocks and bonds</span>.”</span> <em><span>Journal of Financial Economics</span></em> 33 (1): 3–56. <a href="https://doi.org/10.1016/0304-405X(93)90023-5">https://doi.org/10.1016/0304-405X(93)90023-5</a>.
</div>
<div id="ref-Hastie2013" class="csl-entry" role="listitem">
Gareth, James, Witten Daniela, Hastie Trevor, and Tibshirani Robert. 2013. <em><span class="nocase">An introduction to statistical learning: With applications in R</span></em>. Springer.
</div>
<div id="ref-Harvey2017" class="csl-entry" role="listitem">
Harvey, Campbell R. 2017. <span>“<span class="nocase">Presidential address: The scientific outlook in financial economics</span>.”</span> <em><span>The Journal of Finance</span></em> 72 (4): 1399–1440. <a href="https://doi.org/10.1111/jofi.12530">https://doi.org/10.1111/jofi.12530</a>.
</div>
<div id="ref-Harvey2016" class="csl-entry" role="listitem">
Harvey, Campbell R., Yan Liu, and Heqing Zhu. 2016. <span>“<span class="nocase"><span class="math inline">\(\ldots\)</span> and the cross-section of expected returns</span>.”</span> <em><span>Review of Financial Studies</span></em> 29 (1): 5–68. <a href="https://doi.org/10.1093/rfs/hhv059">https://doi.org/10.1093/rfs/hhv059</a>.
</div>
<div id="ref-Hastie2009" class="csl-entry" role="listitem">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em><span class="nocase">The elements of statistical learning: Data mining, inference and prediction</span></em>. 2nd ed. Springer. <a href="https://hastie.su.domains/ElemStatLearn/">https://hastie.su.domains/ElemStatLearn/</a>.
</div>
<div id="ref-Hoerl1970" class="csl-entry" role="listitem">
Hoerl, Arthur E., and Robert W. Kennard. 1970. <span>“<span class="nocase">Ridge regression: Applications to nonorthogonal problems</span>.”</span> <em><span>Technometrics</span></em> 12 (1): 69–82. <a href="https://doi.org/1267352">https://doi.org/1267352</a>.
</div>
<div id="ref-Hou2015" class="csl-entry" role="listitem">
Hou, Kewei, Chen Xue, and Lu Zhang. 2014. <span>“<span class="nocase">Digesting anomalies: An investment approach</span>.”</span> <em><span>Review of Financial Studies</span></em> 28 (3): 650–705. <a href="https://doi.org/10.1093/rfs/hhu068">https://doi.org/10.1093/rfs/hhu068</a>.
</div>
<div id="ref-Hou2020" class="csl-entry" role="listitem">
———. 2020. <span>“<span class="nocase">Replicating anomalies</span>.”</span> <em><span>Review of Financial Studies</span></em> 33 (5): 2019–2133. <a href="https://doi.org/10.1093/rfs/hhy131">https://doi.org/10.1093/rfs/hhy131</a>.
</div>
<div id="ref-Mclean2016" class="csl-entry" role="listitem">
Mclean, R. David, and Jeffrey Pontiff. 2016. <span>“<span class="nocase">Does academic research destroy stock return predictability?</span>”</span> <em><span>The Journal of Finance</span></em> 71 (1): 5–32. <a href="https://doi.org/10.1111/jofi.12365">https://doi.org/10.1111/jofi.12365</a>.
</div>
<div id="ref-Mullainathan2017" class="csl-entry" role="listitem">
Mullainathan, Sendhil, and Jann Spiess. 2017. <span>“<span class="nocase">Machine learning: An applied econometric approach</span>.”</span> <em><span>Journal of Economic Perspectives</span></em> 31 (2): 87–106. <a href="https://doi.org/10.1257/jep.31.2.87">https://doi.org/10.1257/jep.31.2.87</a>.
</div>
<div id="ref-Nagel2021" class="csl-entry" role="listitem">
Nagel, Stefan. 2021. <em><span class="nocase">Machine learning in asset pricing</span></em>. Princeton University Press.
</div>
<div id="ref-scikit-learn" class="csl-entry" role="listitem">
Pedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, et al. 2011. <span>“Scikit-Learn: Machine Learning in <span>P</span>ython.”</span> <em>Journal of Machine Learning Research</em> 12: 2825–30.
</div>
<div id="ref-Tibshirani1996" class="csl-entry" role="listitem">
Tibshirani, Robert. 1996. <span>“<span class="nocase">Regression shrinkage and selection via the LASSO</span>.”</span> <em><span>Journal of the Royal Statistical Society. Series B (Methodological)</span></em> 58 (1): 267–88. <a href="http://www.jstor.org/stable/2346178">http://www.jstor.org/stable/2346178</a>.
</div>
<div id="ref-Goyal2008" class="csl-entry" role="listitem">
Welch, Ivo, and Amit Goyal. 2008. <span>“<span class="nocase">A comprehensive look at the empirical performance of equity premium prediction</span>.”</span> <em><span>Review of Financial Studies</span></em> 21 (4): 1455–1508. <a href="https://doi.org/10.1093/rfs/hhm014">https://doi.org/10.1093/rfs/hhm014</a>.
</div>
<div id="ref-Zou2005" class="csl-entry" role="listitem">
Zou, Hui, and Trevor Hastie. 2005. <span>“<span class="nocase">Regularization and variable selection via the elastic net</span>.”</span> <em><span>Journal of the Royal Statistical Society. Series B (Statistical Methodology)</span></em> 67 (2): 301–20. <a href="https://www.jstor.org/stable/3647580">https://www.jstor.org/stable/3647580</a>.
</div>
</div></section></div></main> <!-- /main -->
<div class="custom-footer">
  <div class="copyright">© Christoph Frey, Christoph Scheuch, Stefan Voigt &amp; Patrick Weiss</div>
  <a href="disclaimer.html">Disclaimer</a>
  <a href="#" id="open_preferences_center">Cookie Preferences</a>
</div>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.tidy-finance\.org");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../python/difference-in-differences.html" class="pagination-link" aria-label="Difference in Differences">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Difference in Differences</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../python/option-pricing-via-machine-learning.html" class="pagination-link" aria-label="Option Pricing via Machine Learning">
        <span class="nav-page-text">Option Pricing via Machine Learning</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">

<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/tidy-finance/website/blob/main/python/factor-selection-via-machine-learning.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>